import io
import re
import pandas as pd
import streamlit as st
import plotly.express as px

st.set_page_config(page_title="TMSå‡ºè²¨é…é€æ•¸æ“šåˆ†æ", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š TMSå‡ºè²¨é…é€æ•¸æ“šåˆ†æ")
st.caption("ä¸Šå‚³ Excel/CSV â†’ å‡ºè²¨é¡å‹ç­†æ•¸ï¼ˆéŠ…é‡é‡æ›ç®—å™¸ï¼‰â†’ é…é€é”äº¤ç‡ï¼ˆåƒ…æ—¥æœŸï¼Œæ’é™¤SWI-å¯„åº«ï¼‰â†’ é…é€å€åŸŸåˆ†æ â†’ é…é€è£è¼‰åˆ†æï¼ˆåƒ…å®Œæˆï¼‰")

# ---------- æª”æ¡ˆä¸Šå‚³ ----------
file = st.file_uploader(
    "ä¸Šå‚³ Excel æˆ– CSV æª”", type=["xlsx", "xls", "csv"],
    help="æœ€å¤š 200 MBï¼›Excel éœ€ä½¿ç”¨ openpyxl è§£æ"
)

@st.cache_data
def load_data(file):
    if file.name.lower().endswith(".csv"):
        df = pd.read_csv(file)
    else:
        df = pd.read_excel(file, engine="openpyxl")
    return df

# ---------- å·¥å…·å‡½å¼ ----------
def _guess_col(cols, keywords):
    for kw in keywords:
        for c in cols:
            if kw in str(c):
                return c
    return None

def to_dt(series):
    return pd.to_datetime(series, errors="coerce")

def extract_city(addr):
    """å¾åœ°å€å­—ä¸²ä¸­æ“·å–å°ç£ç¸£å¸‚ï¼ˆå°‡ã€è‡ºã€æ­£è¦åŒ–ç‚ºã€å°ã€ï¼‰ï¼Œå¤±æ•—å›å‚³ Noneã€‚"""
    if pd.isna(addr):
        return None
    s = str(addr).strip().replace("è‡º", "å°")
    pattern = r"(å°åŒ—å¸‚|æ–°åŒ—å¸‚|æ¡ƒåœ’å¸‚|å°ä¸­å¸‚|å°å—å¸‚|é«˜é›„å¸‚|åŸºéš†å¸‚|æ–°ç«¹å¸‚|æ–°ç«¹ç¸£|è‹—æ —ç¸£|å½°åŒ–ç¸£|å—æŠ•ç¸£|é›²æ—ç¸£|å˜‰ç¾©å¸‚|å˜‰ç¾©ç¸£|å±æ±ç¸£|å®œè˜­ç¸£|èŠ±è“®ç¸£|å°æ±ç¸£|æ¾æ¹–ç¸£|é‡‘é–€ç¸£|é€£æ±Ÿç¸£)"
    m = re.search(pattern, s)
    return m.group(1) if m else None

# ======================== ä¸»æµç¨‹ ========================
if file:
    df = load_data(file)

    # ---- è‡ªå‹•æ¬„ä½åµæ¸¬ï¼ˆä¸é¡¯ç¤º UIï¼‰ ----
    cols = list(df.columns)
    ship_type_col     = _guess_col(cols, ["å‡ºè²¨ç”³è«‹é¡å‹", "å‡ºè²¨é¡å‹", "é…é€é¡å‹", "é¡å‹"])
    due_date_col      = _guess_col(cols, ["æŒ‡å®šåˆ°è²¨æ—¥æœŸ", "åˆ°è²¨æ—¥æœŸ", "æŒ‡å®šåˆ°è²¨", "åˆ°è²¨æ—¥"])
    sign_date_col     = _guess_col(cols, ["å®¢æˆ¶ç°½æ”¶æ—¥æœŸ", "ç°½æ”¶æ—¥æœŸ", "ç°½æ”¶æ—¥", "å®¢æˆ¶ç°½æ”¶æ—¥æœŸ/æ™‚/åˆ†"])
    cust_id_col       = _guess_col(cols, ["å®¢æˆ¶ç·¨è™Ÿ", "å®¢æˆ¶ä»£è™Ÿ", "å®¢ç·¨"])
    cust_name_col     = _guess_col(cols, ["å®¢æˆ¶åç¨±", "å®¢å", "å®¢æˆ¶"])
    address_col       = _guess_col(cols, ["åœ°å€", "æ”¶è²¨åœ°å€", "é€è²¨åœ°å€", "äº¤è²¨åœ°å€"])
    # æ³¨æ„ï¼šå¯¦éš›æ•¸å€¼å–®ä½æ˜¯ kgï¼Œä½†æ¬„åå¯èƒ½ç‚ºã€ŒéŠ…é‡é‡(å™¸)ã€
    copper_ton_col    = _guess_col(cols, ["éŠ…é‡é‡(å™¸)", "éŠ…é‡é‡(å™¸æ•¸)", "éŠ…å™¸", "éŠ…é‡é‡"])
    qty_col           = _guess_col(cols, ["å‡ºè²¨æ•¸é‡", "æ•¸é‡", "å‡ºè²¨é‡"])
    ship_no_col       = _guess_col(cols, ["å‡ºåº«å–®è™Ÿ", "å‡ºåº«å–®", "å‡ºåº«ç·¨è™Ÿ"])
    do_col            = _guess_col(cols, ["DOè™Ÿ", "DO", "å‡ºè²¨å–®è™Ÿ", "äº¤è²¨å–®è™Ÿ"])
    item_desc_col     = _guess_col(cols, ["æ–™è™Ÿèªªæ˜", "å“å", "å“åè¦æ ¼", "ç‰©æ–™èªªæ˜"])
    lot_col           = _guess_col(cols, ["æ‰¹æ¬¡", "æ‰¹è™Ÿ", "Lot"])
    fg_net_ton_col    = _guess_col(cols, ["æˆå“æ·¨é‡(å™¸)", "æˆå“æ·¨é‡(å™¸)", "æ·¨é‡(å™¸)"])
    fg_gross_ton_col  = _guess_col(cols, ["æˆå“æ¯›é‡(å™¸)", "æˆå“æ¯›é‡(å™¸)", "æ¯›é‡(å™¸)"])
    status_col        = _guess_col(cols, ["é€šçŸ¥å–®é …æ¬¡ç‹€æ…‹", "é …æ¬¡ç‹€æ…‹", "ç‹€æ…‹"])

    # Tabsï¼šåˆ†æ / åŸå§‹è³‡æ–™
    tab_analysis, tab_raw = st.tabs(["ğŸ“Š å‡ºè²¨&é”äº¤åˆ†æ", "ğŸ“„ åŸå§‹è³‡æ–™é è¦½"])

    # -------- åŸå§‹è³‡æ–™åˆ†é  --------
    with tab_raw:
        st.subheader("åŸå§‹è³‡æ–™é è¦½")
        st.dataframe(df, use_container_width=True)

    # -------- åˆ†æåˆ†é  --------
    with tab_analysis:
        # ---------- å´æ¬„æ“ä½œï¼ˆå¸¸ç”¨ç¯©é¸ï¼‰ ----------
        with st.sidebar:
            st.header("âš™ï¸ æ“ä½œå€ï¼ˆå¸¸ç”¨ç¯©é¸ï¼‰")

            # å‡ºè²¨ç”³è«‹é¡å‹ï¼ˆç°¡å–®å¤šé¸ï¼‰
            if ship_type_col and ship_type_col in df.columns:
                ship_opts = sorted(df[ship_type_col].dropna().astype(str).unique().tolist())
                sel_types = st.multiselect("å‡ºè²¨ç”³è«‹é¡å‹ï¼ˆå¤šé¸ï¼‰", options=ship_opts, default=[])
            else:
                sel_types = []

            # å®¢æˆ¶åç¨±ï¼ˆå¯æœå°‹å¤šé¸ï¼‰
            if cust_name_col and cust_name_col in df.columns:
                name_opts = sorted(df[cust_name_col].dropna().astype(str).unique().tolist())
                sel_names = st.multiselect("å®¢æˆ¶åç¨±ï¼ˆå¯æœå°‹ï¼‰", options=name_opts, default=[])
            else:
                sel_names = []

            # å®¢æˆ¶ç·¨è™Ÿï¼ˆå¯æœå°‹å¤šé¸ï¼‰
            if cust_id_col and cust_id_col in df.columns:
                id_opts = sorted(df[cust_id_col].dropna().astype(str).unique().tolist())
                sel_ids = st.multiselect("å®¢æˆ¶ç·¨è™Ÿï¼ˆå¯æœå°‹ï¼‰", options=id_opts, default=[])
            else:
                sel_ids = []

            # æŒ‡å®šåˆ°è²¨æ—¥æœŸï¼ˆæ—¥æœŸå€é–“ï¼‰
            if due_date_col and due_date_col in df.columns:
                due_series = to_dt(df[due_date_col])
                min_date = due_series.min().date() if not due_series.dropna().empty else None
                max_date = due_series.max().date() if not due_series.dropna().empty else None
                if min_date and max_date:
                    date_range = st.date_input("æŒ‡å®šåˆ°è²¨æ—¥æœŸï¼ˆå€é–“ï¼‰", value=(min_date, max_date))
                else:
                    date_range = None
            else:
                date_range = None

            # æ–™è™Ÿèªªæ˜ï¼ˆå¯æœå°‹å¤šé¸ï¼‰
            if item_desc_col and item_desc_col in df.columns:
                item_opts = sorted(df[item_desc_col].dropna().astype(str).unique().tolist())
                sel_items = st.multiselect("æ–™è™Ÿèªªæ˜ï¼ˆå¯æœå°‹ï¼‰", options=item_opts, default=[])
            else:
                sel_items = []

            st.markdown("---")

            # å…¶å®ƒï¼šé¸æ“‡è¦ç¯©é¸çš„æ¬„ä½ï¼ˆå¯ç•¥ï¼‰
            filter_col = st.selectbox("é¸æ“‡è¦ç¯©é¸çš„æ¬„ä½ï¼ˆå¯ç•¥ï¼‰", ["ï¼ˆä¸ç¯©é¸ï¼‰"] + cols)
            extra_selected_vals = []
            if filter_col != "ï¼ˆä¸ç¯©é¸ï¼‰":
                unique_vals = df[filter_col].dropna().unique().tolist()
                extra_selected_vals = st.multiselect("é¸å–å€¼ï¼ˆå¯å¤šé¸ï¼‰", unique_vals)

            # æ¯å®¢æˆ¶ Top N ç¸£å¸‚ï¼ˆä¾›â‘¢ä½¿ç”¨ï¼‰
            topn_cities = st.slider("æ¯å®¢æˆ¶ Top N ç¸£å¸‚ï¼ˆâ‘¢ç”¨ï¼‰", min_value=1, max_value=10, value=3, step=1)

        # ---- å¥—ç”¨ç¯©é¸ ----
        data = df.copy()

        if sel_types and (ship_type_col in data.columns):
            data = data[data[ship_type_col].astype(str).isin(sel_types)]

        if sel_names and (cust_name_col in data.columns):
            data = data[data[cust_name_col].astype(str).isin(sel_names)]

        if sel_ids and (cust_id_col in data.columns):
            data = data[data[cust_id_col].astype(str).isin(sel_ids)]

        if date_range and (due_date_col in data.columns):
            due_day_all = to_dt(data[due_date_col]).dt.normalize()
            start_d, end_d = pd.to_datetime(date_range[0]), pd.to_datetime(date_range[1])
            data = data[(due_day_all >= start_d) & (due_day_all <= end_d)]

        if sel_items and (item_desc_col in data.columns):
            data = data[data[item_desc_col].astype(str).isin(sel_items)]

        if filter_col != "ï¼ˆä¸ç¯©é¸ï¼‰" and extra_selected_vals:
            data = data[data[filter_col].isin(extra_selected_vals)]

        # å…±ç”¨ï¼šæ’é™¤ SWI-å¯„åº«ï¼ˆä¾› â‘¡/â‘¢/â‘£ ä½¿ç”¨ï¼‰
        exclude_swi_mask = pd.Series(True, index=data.index)
        if ship_type_col in data.columns:
            exclude_swi_mask = data[ship_type_col] != "SWI-å¯„åº«"

        # =====================================================
        # â‘  å‡ºè²¨é¡å‹ç­†æ•¸çµ±è¨ˆï¼ˆå«éŠ…é‡é‡æ›ç®—å™¸ï¼›ã€ŒéŠ…é‡é‡(å™¸)ã€æ¬„ä½å¯¦éš›å–®ä½=kgï¼‰
        # =====================================================
        st.subheader("â‘  å‡ºè²¨é¡å‹ç­†æ•¸çµ±è¨ˆ")
        if ship_type_col in data.columns:
            type_counts = (
                data[ship_type_col]
                .fillna("(ç©ºç™½)")
                .value_counts(dropna=False)
                .rename_axis("å‡ºè²¨é¡å‹")
                .reset_index(name="ç­†æ•¸")
            )
            total_rows = int(type_counts["ç­†æ•¸"].sum())

            # éŠ…é‡é‡åˆè¨ˆï¼ˆkgï¼‰â†’ é¡¯ç¤ºæˆã€Œå™¸ã€
            if copper_ton_col in data.columns:
                data["_copper_kg"] = pd.to_numeric(data[copper_ton_col], errors="coerce")
                copper_sum_kg = (
                    data.groupby(ship_type_col)["_copper_kg"]
                    .sum(min_count=1)
                    .reset_index()
                    .rename(columns={"_copper_kg": "éŠ…é‡é‡(kg)åˆè¨ˆ"})
                )
                merged = type_counts.merge(copper_sum_kg, how="left",
                                           left_on="å‡ºè²¨é¡å‹", right_on=ship_type_col)
                if ship_type_col in merged.columns:
                    merged.drop(columns=[ship_type_col], inplace=True)

                merged["éŠ…é‡é‡(å™¸)åˆè¨ˆ"] = (
                    pd.to_numeric(merged["éŠ…é‡é‡(kg)åˆè¨ˆ"], errors="coerce") / 1000.0
                ).round(2)
                merged.drop(columns=["éŠ…é‡é‡(kg)åˆè¨ˆ"], inplace=True)
            else:
                merged = type_counts.copy()
                merged["éŠ…é‡é‡(å™¸)åˆè¨ˆ"] = None

            # â€”â€” KPI å¡ç‰‡ â€”â€”ï¼ˆst.metricï¼‰
            k1, k2 = st.columns(2)
            k1.metric("è³‡æ–™ç­†æ•¸", f"{total_rows:,}")
            total_copper_ton_all = (
                pd.to_numeric(merged["éŠ…é‡é‡(å™¸)åˆè¨ˆ"], errors="coerce").sum()
                if "éŠ…é‡é‡(å™¸)åˆè¨ˆ" in merged.columns else 0.0
            )
            k2.metric("ç¸½éŠ…é‡é‡(å™¸)", f"{total_copper_ton_all:,.2f}")

            # â€”â€” åœ–è¡¨é¸æ“‡ï¼šé•·æ¢ / åœ“é¤… / ç’°å½¢ï¼ˆåœ“é¤…/ç’°å½¢é¡¯ç¤ºç™¾åˆ†æ¯”ï¼‰â€”â€”
            chart_choice = st.radio("åœ–è¡¨é¡å‹", ["é•·æ¢åœ–", "åœ“é¤…åœ–", "ç’°å½¢åœ–"], horizontal=True)
            neutral_colors = ["#7f8c8d", "#95a5a6", "#bdc3c7", "#dfe6e9", "#b2bec3", "#636e72", "#ced6e0"]

            c1, c2 = st.columns([1, 1])
            with c1:
                st.dataframe(merged, use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰å‡ºè²¨é¡å‹çµ±è¨ˆ CSV",
                    data=merged.to_csv(index=False).encode("utf-8-sig"),
                    file_name="å‡ºè²¨é¡å‹_çµ±è¨ˆ.csv",
                    mime="text/csv",
                )
            with c2:
                if not type_counts.empty:
                    if chart_choice == "é•·æ¢åœ–":
                        fig = px.bar(type_counts, x="å‡ºè²¨é¡å‹", y="ç­†æ•¸")
                    else:
                        hole_size = 0.0 if chart_choice == "åœ“é¤…åœ–" else 0.5
                        fig = px.pie(
                            type_counts,
                            names="å‡ºè²¨é¡å‹",
                            values="ç­†æ•¸",
                            color_discrete_sequence=neutral_colors,
                            hole=hole_size,
                        )
                        fig.update_traces(textinfo="percent+label")
                    st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("æ‰¾ä¸åˆ°ã€å‡ºè²¨ç”³è«‹é¡å‹ã€æ¬„ä½ï¼Œè«‹ç¢ºèªä¸Šå‚³æª”æ¡ˆæ¬„åã€‚")

        st.markdown("---")

        # =====================================================
        # â‘¡ é…é€é”äº¤ç‡ï¼ˆåƒ…æ¯”å°æ—¥æœŸï¼Œä¸å«æ™‚åˆ†ç§’ï¼›æ’é™¤ SWI-å¯„åº«ï¼‰
        # =====================================================
        st.subheader("â‘¡ é…é€é”äº¤ç‡ï¼ˆåƒ…æ¯”å°æ—¥æœŸï¼Œä¸å«æ™‚åˆ†ç§’ï¼‰")
        if (due_date_col in data.columns) and (sign_date_col in data.columns):
            due_dt = to_dt(data[due_date_col])
            sign_dt = to_dt(data[sign_date_col])
            due_day = due_dt.dt.normalize()
            sign_day = sign_dt.dt.normalize()

            valid_mask = due_day.notna() & sign_day.notna() & exclude_swi_mask
            on_time = (sign_day <= due_day) & valid_mask

            total_valid = int(valid_mask.sum())
            on_time_count = int(on_time.sum())
            rate = (on_time_count / total_valid * 100.0) if total_valid > 0 else 0.0

            k1, k2, k3, k4 = st.columns(4)
            k1.metric("æœ‰æ•ˆç­†æ•¸ï¼ˆå…©æ—¥æœŸçš†æœ‰å€¼ï¼‰", f"{total_valid:,}")
            k2.metric("æº–æ™‚äº¤ä»˜ç­†æ•¸", f"{on_time_count:,}")
            k3.metric("é”äº¤ç‡", f"{rate:.2f}%")

            # æœªé”æ¨™ï¼ˆé²äº¤ï¼‰æ¸…å–® + å»¶é²å¤©æ•¸ + å¹³å‡å»¶é²å¤©æ•¸
            late_mask = valid_mask & (sign_day > due_day)
            delay_days = (sign_day - due_day).dt.days
            late_df = pd.DataFrame({
                "å®¢æˆ¶ç·¨è™Ÿ": data[cust_id_col] if cust_id_col in data.columns else None,
                "å®¢æˆ¶åç¨±": data[cust_name_col] if cust_name_col in data.columns else None,
                "æŒ‡å®šåˆ°è²¨æ—¥æœŸ": due_day.dt.strftime("%Y-%m-%d"),
                "å®¢æˆ¶ç°½æ”¶æ—¥æœŸ": sign_day.dt.strftime("%Y-%m-%d"),
                "å»¶é²å¤©æ•¸": delay_days,
            })[late_mask]

            avg_delay = float(late_df["å»¶é²å¤©æ•¸"].mean()) if not late_df.empty else 0.0
            k4.metric("å¹³å‡å»¶é²å¤©æ•¸", f"{avg_delay:.2f}")

            st.write("**æœªé”æ¨™æ¸…å–®**ï¼ˆå·²æ’é™¤SWI-å¯„åº«ï¼›åƒ…åˆ—ç°½æ”¶æ™šæ–¼æŒ‡å®šåˆ°è²¨è€…ï¼‰")
            st.dataframe(late_df, use_container_width=True)
            st.download_button(
                "ä¸‹è¼‰æœªé”æ¨™æ¸…å–® CSV",
                data=late_df.to_csv(index=False).encode("utf-8-sig"),
                file_name="æœªé”æ¨™æ¸…å–®.csv",
                mime="text/csv",
            )

            # ä¾å®¢æˆ¶åç¨±ï¼šæœªé”äº¤ç­†æ•¸èˆ‡æ¯”ä¾‹ï¼ˆåƒ…é¡¯ç¤ºæœªé”äº¤ > 0ï¼‰
            if cust_name_col in data.columns:
                tmp = pd.DataFrame({
                    "å®¢æˆ¶åç¨±": data[cust_name_col],
                    "æ˜¯å¦æœ‰æ•ˆ": valid_mask,
                    "æ˜¯å¦é²äº¤": late_mask,
                })
                grp = tmp.groupby("å®¢æˆ¶åç¨±")
                stats = grp["æ˜¯å¦æœ‰æ•ˆ"].sum().to_frame(name="æœ‰æ•ˆç­†æ•¸")
                stats["æœªé”äº¤ç­†æ•¸"] = grp["æ˜¯å¦é²äº¤"].sum()
                stats = stats[stats["æœªé”äº¤ç­†æ•¸"] > 0]
                stats["æœªé”äº¤æ¯”ä¾‹(%)"] = (stats["æœªé”äº¤ç­†æ•¸"] / stats["æœ‰æ•ˆç­†æ•¸"] * 100).round(2)
                stats = stats.reset_index().sort_values(["æœªé”äº¤ç­†æ•¸", "æœªé”äº¤æ¯”ä¾‹(%)"], ascending=[False, False])

                st.write("**ä¾å®¢æˆ¶åç¨±çµ±è¨ˆï¼šæœªé”äº¤ç­†æ•¸èˆ‡æ¯”ä¾‹ï¼ˆ>0ï¼‰**")
                st.dataframe(stats, use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰æœªé”äº¤çµ±è¨ˆï¼ˆå®¢æˆ¶ï¼‰ CSV",
                    data=stats.to_csv(index=False).encode("utf-8-sig"),
                    file_name="æœªé”äº¤çµ±è¨ˆ_ä¾å®¢æˆ¶.csv",
                    mime="text/csv",
                )
        else:
            st.warning("æ‰¾ä¸åˆ°ã€æŒ‡å®šåˆ°è²¨æ—¥æœŸã€æˆ–ã€å®¢æˆ¶ç°½æ”¶æ—¥æœŸã€æ¬„ä½ã€‚")

        st.markdown("---")

        # =====================================================
        # â‘¢ é…é€å€åŸŸåˆ†æï¼ˆæ’é™¤ SWI-å¯„åº«ï¼‰
        # =====================================================
        st.subheader("â‘¢ é…é€å€åŸŸåˆ†æï¼ˆæ’é™¤ SWI-å¯„åº«ï¼‰")
        if address_col in data.columns:
            region_df = data[exclude_swi_mask].copy()
            region_df["ç¸£å¸‚"] = region_df[address_col].apply(extract_city)
            region_df["ç¸£å¸‚"] = region_df["ç¸£å¸‚"].fillna("(æœªçŸ¥)")

            # å„ç¸£å¸‚é…é€ç­†æ•¸ + ä½”æ¯”
            city_counts = (
                region_df["ç¸£å¸‚"].value_counts(dropna=False)
                .rename_axis("ç¸£å¸‚").reset_index(name="ç­†æ•¸")
            )
            total_city = int(city_counts["ç­†æ•¸"].sum()) if not city_counts.empty else 0
            city_counts["ç¸£å¸‚ä½”æ¯”(%)"] = (
                (city_counts["ç­†æ•¸"] / total_city * 100).round(2) if total_city > 0 else 0
            )

            c1, c2 = st.columns([1, 1])
            with c1:
                st.write("**å„ç¸£å¸‚é…é€ç­†æ•¸**")
                st.dataframe(city_counts, use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰å„ç¸£å¸‚é…é€ç­†æ•¸ CSV",
                    data=city_counts.to_csv(index=False).encode("utf-8-sig"),
                    file_name="å„ç¸£å¸‚é…é€ç­†æ•¸.csv",
                    mime="text/csv",
                )
            with c2:
                if not city_counts.empty:
                    fig_city = px.bar(city_counts, x="ç¸£å¸‚", y="ç­†æ•¸")
                    st.plotly_chart(fig_city, use_container_width=True)

            # å„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚ï¼ˆæ¯å®¢æˆ¶ Top Nï¼‰
            if cust_name_col in region_df.columns:
                cust_city = (
                    region_df.groupby([cust_name_col, "ç¸£å¸‚"]).size()
                    .reset_index(name="ç­†æ•¸")
                )
                cust_city["å®¢æˆ¶ç¸½ç­†æ•¸"] = cust_city.groupby(cust_name_col)["ç­†æ•¸"].transform("sum")
                cust_city["ç¸£å¸‚ä½”æ¯”(%)"] = (cust_city["ç­†æ•¸"] / cust_city["å®¢æˆ¶ç¸½ç­†æ•¸"] * 100).round(2)
                cust_city = cust_city.sort_values([cust_name_col, "ç­†æ•¸"], ascending=[True, False])
                top_table = cust_city.groupby(cust_name_col).head(topn_cities)

                st.write(f"**å„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚ï¼ˆæ¯å®¢æˆ¶ Top {topn_cities}ï¼‰**")
                st.dataframe(top_table.rename(columns={cust_name_col: "å®¢æˆ¶åç¨±"}), use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰å„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚ CSV",
                    data=top_table.to_csv(index=False).encode("utf-8-sig"),
                    file_name="å„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚_TopN.csv",
                    mime="text/csv",
                )
        else:
            st.warning("æ‰¾ä¸åˆ°ã€åœ°å€ã€æ¬„ä½ã€‚")

        st.markdown("---")

        # =====================================================
        # â‘£ é…é€è£è¼‰åˆ†æï¼ˆå‡ºåº«å–®è™Ÿå‰13ç¢¼=åŒè»Šï¼›æ’é™¤ SWI-å¯„åº«ï¼›åƒ…ã€å®Œæˆã€ï¼‰
        # =====================================================
        st.subheader("â‘£ é…é€è£è¼‰åˆ†æï¼ˆå‡ºåº«å–®è™Ÿå‰13ç¢¼=åŒè»Šï¼›æ’é™¤ SWI-å¯„åº«ï¼›åƒ…å®Œæˆï¼‰")
        if ship_no_col in data.columns:
            # åƒ…åˆ†æã€Œé€šçŸ¥å–®é …æ¬¡ç‹€æ…‹ï¼å®Œæˆã€ä¸”æ’é™¤ SWI-å¯„åº«
            if status_col in data.columns:
                status_mask = data[status_col].astype(str).str.strip() == "å®Œæˆ"
                base_mask = exclude_swi_mask & status_mask
            else:
                st.info("æœªå°æ‡‰åˆ°ã€é€šçŸ¥å–®é …æ¬¡ç‹€æ…‹ã€æ¬„ä½ï¼Œå°‡ä¸å¥—ç”¨ã€Œå®Œæˆã€éæ¿¾ã€‚")
                base_mask = exclude_swi_mask

            load_df = data[base_mask].copy()
            load_df["è»Šæ¬¡ä»£ç¢¼"] = load_df[ship_no_col].astype(str).str[:13]  # åˆ†è»Šç”¨ï¼Œæ¸…å–®ä»é¡¯ç¤ºå®Œæ•´å‡ºåº«å–®è™Ÿ

            # æ•¸å€¼è½‰æ›
            load_df["_qty_num"] = pd.to_numeric(load_df[qty_col], errors="coerce") if (qty_col in load_df.columns) else pd.Series(dtype="float64", index=load_df.index)
            load_df["_copper_kg"] = pd.to_numeric(load_df[copper_ton_col], errors="coerce") if (copper_ton_col in load_df.columns) else pd.Series(dtype="float64", index=load_df.index)
            load_df["_copper_ton"] = load_df["_copper_kg"] / 1000.0
            load_df["_fg_net_ton"] = pd.to_numeric(load_df[fg_net_ton_col], errors="coerce") if (fg_net_ton_col in load_df.columns) else pd.Series(dtype="float64", index=load_df.index)
            load_df["_fg_gross_ton"] = pd.to_numeric(load_df[fg_gross_ton_col], errors="coerce") if (fg_gross_ton_col in load_df.columns) else pd.Series(dtype="float64", index=load_df.index)

            # æ˜ç´°æ¸…å–®
            wanted = [
                ("è»Šæ¬¡ä»£ç¢¼", "è»Šæ¬¡ä»£ç¢¼"),
                (ship_no_col, "å‡ºåº«å–®è™Ÿ"),
                (do_col, "DOè™Ÿ"),
                (item_desc_col, "æ–™è™Ÿèªªæ˜"),
                (lot_col, "æ‰¹æ¬¡"),
                ("_qty_num", "å‡ºè²¨æ•¸é‡"),
                ("_copper_ton", "éŠ…é‡é‡(å™¸)"),
                ("_fg_net_ton", "æˆå“æ·¨é‡(å™¸)"),
                ("_fg_gross_ton", "æˆå“æ¯›é‡(å™¸)"),
            ]
            display_cols, used_names = {}, set()
            for src, nice in wanted:
                if isinstance(src, str) and (src in load_df.columns):
                    name = nice
                    i = 2
                    while name in used_names:
                        name = f"{nice} ({i})"; i += 1
                    display_cols[name] = load_df[src]; used_names.add(name)

            if display_cols:
                display_df = pd.DataFrame(display_cols)
                for c in ["å‡ºè²¨æ•¸é‡", "éŠ…é‡é‡(å™¸)", "æˆå“æ·¨é‡(å™¸)", "æˆå“æ¯›é‡(å™¸)"]:
                    if c in display_df.columns:
                        display_df[c] = pd.to_numeric(display_df[c], errors="coerce").round(3)
                sort_keys = [c for c in ["è»Šæ¬¡ä»£ç¢¼", "å‡ºåº«å–®è™Ÿ"] if c in display_df.columns]
                if sort_keys:
                    display_df = display_df.sort_values(by=sort_keys).reset_index(drop=True)

                st.write("**é…é€è£è¼‰æ¸…å–®ï¼ˆä¾è»Šæ¬¡ä»£ç¢¼åˆ†è»Šï¼›åƒ…å®Œæˆï¼‰**")
                st.dataframe(display_df, use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰é…é€è£è¼‰æ¸…å–® CSV",
                    data=display_df.to_csv(index=False).encode("utf-8-sig"),
                    file_name="é…é€è£è¼‰æ¸…å–®.csv",
                    mime="text/csv",
                )
            else:
                st.info("ç›®å‰ç„¡å¯é¡¯ç¤ºæ¬„ä½ï¼Œè«‹ç¢ºèªåŸå§‹è³‡æ–™ã€‚")

            # è»Šæ¬¡å½™ç¸½ï¼ˆæ¯è»Šå°è¨ˆï¼‰
            group = load_df.groupby("è»Šæ¬¡ä»£ç¢¼", dropna=False)
            agg_dict = {
                "å‡ºè²¨æ•¸é‡å°è¨ˆ": ("_qty_num", "sum"),
                "éŠ…é‡é‡(kg)_å°è¨ˆ": ("_copper_kg", "sum"),
                "æˆå“æ·¨é‡(å™¸)_å°è¨ˆ": ("_fg_net_ton", "sum"),
                "æˆå“æ¯›é‡(å™¸)_å°è¨ˆ": ("_fg_gross_ton", "sum"),
            }
            summary = group.agg(**agg_dict).reset_index()
            if "éŠ…é‡é‡(kg)_å°è¨ˆ" in summary.columns:
                summary["éŠ…é‡é‡(å™¸)_å°è¨ˆ"] = (pd.to_numeric(summary["éŠ…é‡é‡(kg)_å°è¨ˆ"], errors="coerce") / 1000.0).round(3)
            for c in ["å‡ºè²¨æ•¸é‡å°è¨ˆ", "éŠ…é‡é‡(kg)_å°è¨ˆ", "æˆå“æ·¨é‡(å™¸)_å°è¨ˆ", "æˆå“æ¯›é‡(å™¸)_å°è¨ˆ", "éŠ…é‡é‡(å™¸)_å°è¨ˆ"]:
                if c in summary.columns:
                    summary[c] = pd.to_numeric(summary[c], errors="coerce").round(3)

            st.write("**è»Šæ¬¡å½™ç¸½ï¼ˆæ¯è»Šå°è¨ˆï¼›åƒ…å®Œæˆï¼‰**")
            st.dataframe(summary, use_container_width=True)
            st.download_button(
                "ä¸‹è¼‰è»Šæ¬¡å½™ç¸½ CSV",
                data=summary.to_csv(index=False).encode("utf-8-sig"),
                file_name="è»Šæ¬¡å½™ç¸½.csv",
                mime="text/csv",
            )

            # KPIï¼šå¹³å‡è»Šå­è¼‰é‡(å™¸)ï¼ˆåƒ…è¨ˆå…¥éŠ…é‡é‡>0çš„è»Šæ¬¡ï¼‰
            if "éŠ…é‡é‡(å™¸)_å°è¨ˆ" in summary.columns:
                valid = summary[pd.to_numeric(summary["éŠ…é‡é‡(å™¸)_å°è¨ˆ"], errors="coerce") > 0]
                avg_load = float(valid["éŠ…é‡é‡(å™¸)_å°è¨ˆ"].mean()) if not valid.empty else 0.0
                k1, k2 = st.columns(2)
                k1.metric("ç´å…¥è¨ˆç®—è»Šæ¬¡", f"{len(valid):,}")
                k2.metric("å¹³å‡è»Šå­è¼‰é‡(å™¸)", f"{avg_load:.2f}")
        else:
            st.warning("æ‰¾ä¸åˆ°ã€å‡ºåº«å–®è™Ÿã€æ¬„ä½ã€‚")

else:
    st.info("è«‹å…ˆåœ¨ä¸Šæ–¹ä¸Šå‚³ Excel æˆ– CSV æª”ã€‚")
