import io
import pandas as pd
import streamlit as st
import plotly.express as px
import re

st.set_page_config(page_title="TMSå‡ºè²¨é…é€æ•¸æ“šåˆ†æ", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š TMSå‡ºè²¨é…é€æ•¸æ“šåˆ†æ")
st.caption("ä¸Šå‚³ Excel/CSV â†’ å‡ºè²¨é¡å‹ç­†æ•¸ â†’ é”äº¤ç‡ï¼ˆæ—¥æœŸæ¯”è¼ƒï¼‰â†’ é…é€å€åŸŸåˆ†æ â†’ è‡ªè¨‚æ¬„ä½ â†’ èšåˆ â†’ åœ–è¡¨ â†’ ä¸‹è¼‰")

# ---------- æª”æ¡ˆä¸Šå‚³ ----------
file = st.file_uploader("ä¸Šå‚³ Excel æˆ– CSV æª”", type=["xlsx", "xls", "csv"],
                        help="æœ€å¤š 200 MBï¼›Excel éœ€ä½¿ç”¨ openpyxl è§£æ")

@st.cache_data
def load_data(file):
    if file.name.lower().endswith(".csv"):
        df = pd.read_csv(file)
    else:
        df = pd.read_excel(file, engine="openpyxl")
    return df

def _guess_col(cols, keywords):
    for kw in keywords:
        for c in cols:
            if kw in str(c):
                return c
    return None

def to_dt(series):
    return pd.to_datetime(series, errors="coerce")

def extract_city(addr: object) -> str | None:
    if pd.isna(addr):
        return None
    s = str(addr).strip().replace("è‡º", "å°")
    pattern = r"(å°åŒ—å¸‚|æ–°åŒ—å¸‚|æ¡ƒåœ’å¸‚|å°ä¸­å¸‚|å°å—å¸‚|é«˜é›„å¸‚|åŸºéš†å¸‚|æ–°ç«¹å¸‚|æ–°ç«¹ç¸£|è‹—æ —ç¸£|å½°åŒ–ç¸£|å—æŠ•ç¸£|é›²æ—ç¸£|å˜‰ç¾©å¸‚|å˜‰ç¾©ç¸£|å±æ±ç¸£|å®œè˜­ç¸£|èŠ±è“®ç¸£|å°æ±ç¸£|æ¾æ¹–ç¸£|é‡‘é–€ç¸£|é€£æ±Ÿç¸£)"
    m = re.search(pattern, s)
    return m.group(1) if m else None

if file:
    df = load_data(file)

    # Tabs
    tab_analysis, tab_raw = st.tabs(["ğŸ“Š å‡ºè²¨&é”äº¤åˆ†æ", "ğŸ“„ åŸå§‹è³‡æ–™é è¦½"])

    with tab_raw:
        st.subheader("åŸå§‹è³‡æ–™é è¦½")
        st.dataframe(df, use_container_width=True)

    with tab_analysis:
        # ---------- å´æ¬„æ“ä½œ ----------
        with st.sidebar:
            st.header("âš™ï¸ æ“ä½œå€")
            cols = list(df.columns)

            filter_col = st.selectbox("é¸æ“‡è¦ç¯©é¸çš„æ¬„ä½ï¼ˆå¯ç•¥ï¼‰", ["ï¼ˆä¸ç¯©é¸ï¼‰"] + cols)
            filtered = df.copy()
            if filter_col != "ï¼ˆä¸ç¯©é¸ï¼‰":
                unique_vals = filtered[filter_col].dropna().unique().tolist()
                selected_vals = st.multiselect("é¸å–å€¼", unique_vals)
                if selected_vals:
                    filtered = filtered[filtered[filter_col].isin(selected_vals)]

            st.markdown("â€”")
            st.subheader("æ¬„ä½å°æ‡‰")
            ship_type_col = st.selectbox("å‡ºè²¨é¡å‹æ¬„ä½", options=cols)
            due_date_col = st.selectbox("æŒ‡å®šåˆ°è²¨æ—¥æœŸæ¬„ä½", options=cols)
            sign_date_col = st.selectbox("å®¢æˆ¶ç°½æ”¶æ—¥æœŸæ¬„ä½", options=cols)
            cust_id_col = st.selectbox("å®¢æˆ¶ç·¨è™Ÿæ¬„ä½", options=cols)
            cust_name_col = st.selectbox("å®¢æˆ¶åç¨±æ¬„ä½", options=cols)
            address_col = st.selectbox("åœ°å€æ¬„ä½", options=cols)

        data = filtered.copy()

        # ---------- åŠŸèƒ½â‘  å‡ºè²¨é¡å‹ç­†æ•¸ ----------
        st.subheader("â‘  å‡ºè²¨é¡å‹ç­†æ•¸çµ±è¨ˆ")
        type_counts = (
            data[ship_type_col].fillna("(ç©ºç™½)").value_counts(dropna=False)
            .rename_axis("å‡ºè²¨é¡å‹").reset_index(name="ç­†æ•¸")
        )
        total_rows = int(type_counts["ç­†æ•¸"].sum())
        st.write(f"**åŠ ç¸½ç­†æ•¸ï¼š{total_rows:,}**")
        st.dataframe(type_counts, use_container_width=True)

        # ---------- åŠŸèƒ½â‘¡ é”äº¤ç‡ ----------
        st.subheader("â‘¡ é”äº¤ç‡ï¼ˆåƒ…æ¯”å°æ—¥æœŸï¼Œä¸å«æ™‚åˆ†ç§’ï¼‰")
        due_dt = to_dt(data[due_date_col])
        sign_dt = to_dt(data[sign_date_col])
        due_day = due_dt.dt.normalize()
        sign_day = sign_dt.dt.normalize()

        exclude_mask = data[ship_type_col] != "SWI-å¯„åº«"
        valid_mask = due_day.notna() & sign_day.notna() & exclude_mask
        on_time = (sign_day <= due_day) & valid_mask

        total_valid = int(valid_mask.sum())
        on_time_count = int(on_time.sum())
        rate = (on_time_count / total_valid * 100.0) if total_valid > 0 else 0.0

        k1, k2, k3, k4 = st.columns(4)
        k1.metric("æœ‰æ•ˆç­†æ•¸", f"{total_valid:,}")
        k2.metric("æº–æ™‚äº¤ä»˜ç­†æ•¸", f"{on_time_count:,}")
        k3.metric("é”äº¤ç‡", f"{rate:.2f}%")

        late_mask = valid_mask & (sign_day > due_day)
        delay_days = (sign_day - due_day).dt.days
        late_df = pd.DataFrame({
            "å®¢æˆ¶ç·¨è™Ÿ": data[cust_id_col],
            "å®¢æˆ¶åç¨±": data[cust_name_col],
            "æŒ‡å®šåˆ°è²¨æ—¥æœŸ": due_day.dt.strftime("%Y-%m-%d"),
            "å®¢æˆ¶ç°½æ”¶æ—¥æœŸ": sign_day.dt.strftime("%Y-%m-%d"),
            "å»¶é²å¤©æ•¸": delay_days,
        })[late_mask]
        avg_delay = float(late_df["å»¶é²å¤©æ•¸"].mean()) if not late_df.empty else 0.0
        k4.metric("å¹³å‡å»¶é²å¤©æ•¸", f"{avg_delay:.2f}")
        st.dataframe(late_df, use_container_width=True)

        # ---------- åŠŸèƒ½â‘¢ é…é€å€åŸŸåˆ†æ ----------
        st.subheader("â‘¢ é…é€å€åŸŸåˆ†æï¼ˆæ’é™¤ SWI-å¯„åº«ï¼‰")
        region_df = data[exclude_mask].copy()
        region_df["ç¸£å¸‚"] = region_df[address_col].apply(extract_city).fillna("(æœªçŸ¥)")

        # ä¾ç¸£å¸‚çµ±è¨ˆ
        city_counts = region_df["ç¸£å¸‚"].value_counts().rename_axis("ç¸£å¸‚").reset_index(name="ç­†æ•¸")
        st.write("**å„ç¸£å¸‚é…é€ç­†æ•¸**")
        st.dataframe(city_counts, use_container_width=True)

        # å®¢æˆ¶å¸¸å‡ºçš„ç¸£å¸‚
        cust_city = region_df.groupby([cust_name_col, "ç¸£å¸‚"]).size().reset_index(name="ç­†æ•¸")
        cust_city = cust_city.sort_values([cust_name_col, "ç­†æ•¸"], ascending=[True, False])
        top_table = cust_city.groupby(cust_name_col).head(3)
        st.write("**å„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚ï¼ˆTop 3ï¼‰**")
        st.dataframe(top_table.rename(columns={cust_name_col: "å®¢æˆ¶åç¨±"}), use_container_width=True)

else:
    st.info("è«‹å…ˆåœ¨ä¸Šæ–¹ä¸Šå‚³ Excel æˆ– CSV æª”ã€‚")
