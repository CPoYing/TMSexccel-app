import io
import re
import pandas as pd
import streamlit as st
import plotly.express as px

st.set_page_config(page_title="TMSå‡ºè²¨é…é€æ•¸æ“šåˆ†æ", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š TMSå‡ºè²¨é…é€æ•¸æ“šåˆ†æ")
st.caption("ä¸Šå‚³ Excel/CSV â†’ å‡ºè²¨é¡å‹ç­†æ•¸ï¼ˆå«éŠ…é‡é‡kgï¼‰â†’ é”äº¤ç‡ï¼ˆåƒ…æ—¥æœŸï¼Œæ’é™¤SWI-å¯„åº«ï¼‰â†’ é…é€å€åŸŸåˆ†æ â†’ é…é€è£è¼‰åˆ†æ â†’ è‡ªè¨‚æ¬„ä½ â†’ èšåˆ(ç¨ç«‹åˆ†é ) â†’ è¦–è¦ºåŒ–/ä¸‹è¼‰")

# ---------- æª”æ¡ˆä¸Šå‚³ ----------
file = st.file_uploader(
    "ä¸Šå‚³ Excel æˆ– CSV æª”", type=["xlsx", "xls", "csv"],
    help="æœ€å¤š 200 MBï¼›Excel éœ€ä½¿ç”¨ openpyxl è§£æ"
)

@st.cache_data
def load_data(file):
    if file.name.lower().endswith(".csv"):
        df = pd.read_csv(file)
    else:
        df = pd.read_excel(file, engine="openpyxl")
    return df

# ---------- å·¥å…·å‡½å¼ ----------
def _guess_col(cols, keywords):
    for kw in keywords:
        for c in cols:
            if kw in str(c):
                return c
    return None

def to_dt(series):
    return pd.to_datetime(series, errors="coerce")

def extract_city(addr):
    """å¾åœ°å€å­—ä¸²ä¸­æ“·å–å°ç£ç¸£å¸‚ï¼ˆå°‡ã€è‡ºã€æ­£è¦åŒ–ç‚ºã€å°ã€ï¼‰ï¼Œå¤±æ•—å›å‚³ Noneã€‚"""
    if pd.isna(addr):
        return None
    s = str(addr).strip().replace("è‡º", "å°")
    pattern = r"(å°åŒ—å¸‚|æ–°åŒ—å¸‚|æ¡ƒåœ’å¸‚|å°ä¸­å¸‚|å°å—å¸‚|é«˜é›„å¸‚|åŸºéš†å¸‚|æ–°ç«¹å¸‚|æ–°ç«¹ç¸£|è‹—æ —ç¸£|å½°åŒ–ç¸£|å—æŠ•ç¸£|é›²æ—ç¸£|å˜‰ç¾©å¸‚|å˜‰ç¾©ç¸£|å±æ±ç¸£|å®œè˜­ç¸£|èŠ±è“®ç¸£|å°æ±ç¸£|æ¾æ¹–ç¸£|é‡‘é–€ç¸£|é€£æ±Ÿç¸£)"
    m = re.search(pattern, s)
    return m.group(1) if m else None

# ======================== ä¸»æµç¨‹ ========================
if file:
    df = load_data(file)

    # Tabsï¼šåˆ†æ / åŸå§‹è³‡æ–™ / èšåˆçµæœ
    tab_analysis, tab_raw, tab_agg = st.tabs(["ğŸ“Š å‡ºè²¨&é”äº¤åˆ†æ", "ğŸ“„ åŸå§‹è³‡æ–™é è¦½", "ğŸ“¦ è™•ç†å¾Œè³‡æ–™ï¼ˆèšåˆçµæœï¼‰"])

    # -------- åŸå§‹è³‡æ–™åˆ†é  --------
    with tab_raw:
        st.subheader("åŸå§‹è³‡æ–™é è¦½")
        st.dataframe(df, use_container_width=True)

    # -------- åˆ†æåˆ†é  --------
    with tab_analysis:
        # ---------- å´æ¬„æ“ä½œ ----------
        with st.sidebar:
            st.header("âš™ï¸ æ“ä½œå€")
            cols = list(df.columns)

            # ç¯©é¸å™¨ï¼ˆå¯ç•¥ï¼‰
            filter_col = st.selectbox("é¸æ“‡è¦ç¯©é¸çš„æ¬„ä½ï¼ˆå¯ç•¥ï¼‰", ["ï¼ˆä¸ç¯©é¸ï¼‰"] + cols)
            filtered = df.copy()
            if filter_col != "ï¼ˆä¸ç¯©é¸ï¼‰":
                unique_vals = filtered[filter_col].dropna().unique().tolist()
                selected_vals = st.multiselect("é¸å–å€¼", unique_vals)
                if selected_vals:
                    filtered = filtered[filtered[filter_col].isin(selected_vals)]

            st.markdown("â€”")
            st.subheader("æ¬„ä½å°æ‡‰ï¼ˆå»ºè­°å…ˆç¢ºèªï¼‰")
            ship_type_default = _guess_col(cols, ["å‡ºè²¨ç”³è«‹é¡å‹", "å‡ºè²¨é¡å‹", "é…é€é¡å‹", "é¡å‹"]) or (cols[0] if cols else None)
            due_date_default = _guess_col(cols, ["æŒ‡å®šåˆ°è²¨æ—¥æœŸ", "åˆ°è²¨æ—¥æœŸ", "æŒ‡å®šåˆ°è²¨", "åˆ°è²¨æ—¥"]) or (cols[0] if cols else None)
            sign_date_default = _guess_col(cols, ["å®¢æˆ¶ç°½æ”¶æ—¥æœŸ", "ç°½æ”¶æ—¥æœŸ", "ç°½æ”¶æ—¥", "å®¢æˆ¶ç°½æ”¶æ—¥æœŸ/æ™‚/åˆ†"]) or (cols[0] if cols else None)
            cust_id_default = _guess_col(cols, ["å®¢æˆ¶ç·¨è™Ÿ", "å®¢æˆ¶ä»£è™Ÿ", "å®¢ç·¨"]) or (cols[0] if cols else None)
            cust_name_default = _guess_col(cols, ["å®¢æˆ¶åç¨±", "å®¢å", "å®¢æˆ¶"]) or (cols[0] if cols else None)
            address_default = _guess_col(cols, ["åœ°å€", "æ”¶è²¨åœ°å€", "é€è²¨åœ°å€", "äº¤è²¨åœ°å€"]) or (cols[0] if cols else None)

            # ã€ŒéŠ…é‡é‡(å™¸)ã€æ¬„ä½å¯¦éš›å–®ä½ç‚º kgï¼Œé€™è£¡ä»è®“ä½ å°åˆ°è©²æ¬„ä½
            copper_ton_default = _guess_col(cols, ["éŠ…é‡é‡(å™¸)", "éŠ…é‡é‡(å™¸æ•¸)", "éŠ…å™¸", "éŠ…é‡é‡"]) or (cols[0] if cols else None)
            qty_default = _guess_col(cols, ["å‡ºè²¨æ•¸é‡", "æ•¸é‡", "å‡ºè²¨é‡"]) or (cols[0] if cols else None)
            shipno_default = _guess_col(cols, ["å‡ºåº«å–®è™Ÿ", "å‡ºåº«å–®", "å‡ºåº«ç·¨è™Ÿ"]) or (cols[0] if cols else None)
            do_default = _guess_col(cols, ["DOè™Ÿ", "DO", "å‡ºè²¨å–®è™Ÿ", "äº¤è²¨å–®è™Ÿ"]) or (cols[0] if cols else None)
            item_desc_default = _guess_col(cols, ["æ–™è™Ÿèªªæ˜", "å“å", "å“åè¦æ ¼", "ç‰©æ–™èªªæ˜"]) or (cols[0] if cols else None)
            lot_default = _guess_col(cols, ["æ‰¹æ¬¡", "æ‰¹è™Ÿ", "Lot"]) or (cols[0] if cols else None)
            fg_net_ton_default = _guess_col(cols, ["æˆå“æ·¨é‡(å™¸)", "æ·¨é‡(å™¸)"]) or (cols[0] if cols else None)
            fg_gross_ton_default = _guess_col(cols, ["æˆå“æ¯›é‡(å™¸)", "æ¯›é‡(å™¸)"]) or (cols[0] if cols else None)

            ship_type_col = st.selectbox("å‡ºè²¨é¡å‹æ¬„ä½", options=cols, index=(cols.index(ship_type_default) if ship_type_default in cols else 0))
            due_date_col = st.selectbox("æŒ‡å®šåˆ°è²¨æ—¥æœŸæ¬„ä½", options=cols, index=(cols.index(due_date_default) if due_date_default in cols else 0))
            sign_date_col = st.selectbox("å®¢æˆ¶ç°½æ”¶æ—¥æœŸæ¬„ä½", options=cols, index=(cols.index(sign_date_default) if sign_date_default in cols else 0))
            cust_id_col = st.selectbox("å®¢æˆ¶ç·¨è™Ÿæ¬„ä½", options=cols, index=(cols.index(cust_id_default) if cust_id_default in cols else 0))
            cust_name_col = st.selectbox("å®¢æˆ¶åç¨±æ¬„ä½", options=cols, index=(cols.index(cust_name_default) if cust_name_default in cols else 0))
            address_col = st.selectbox("åœ°å€æ¬„ä½", options=cols, index=(cols.index(address_default) if address_default in cols else 0))
            copper_ton_col = st.selectbox("éŠ…é‡é‡(å™¸) æ¬„ä½ï¼ˆå¯¦éš›å–®ä½=kgï¼‰", options=cols, index=(cols.index(copper_ton_default) if copper_ton_default in cols else 0))
            qty_col = st.selectbox("å‡ºè²¨æ•¸é‡ æ¬„ä½", options=cols, index=(cols.index(qty_default) if qty_default in cols else 0))
            ship_no_col = st.selectbox("å‡ºåº«å–®è™Ÿ æ¬„ä½", options=cols, index=(cols.index(shipno_default) if shipno_default in cols else 0))
            do_col = st.selectbox("DOè™Ÿ æ¬„ä½", options=cols, index=(cols.index(do_default) if do_default in cols else 0))
            item_desc_col = st.selectbox("æ–™è™Ÿèªªæ˜ æ¬„ä½", options=cols, index=(cols.index(item_desc_default) if item_desc_default in cols else 0))
            lot_col = st.selectbox("æ‰¹æ¬¡ æ¬„ä½", options=cols, index=(cols.index(lot_default) if lot_default in cols else 0))
            fg_net_ton_col = st.selectbox("æˆå“æ·¨é‡(å™¸) æ¬„ä½", options=cols, index=(cols.index(fg_net_ton_default) if fg_net_ton_default in cols else 0))
            fg_gross_ton_col = st.selectbox("æˆå“æ¯›é‡(å™¸) æ¬„ä½", options=cols, index=(cols.index(fg_gross_ton_default) if fg_gross_ton_default in cols else 0))

            # é…é€å€åŸŸ TopNï¼ˆæ¯å®¢æˆ¶é¡¯ç¤ºå‰å¹¾åç¸£å¸‚ï¼‰
            topn = st.slider("æ¯å®¢æˆ¶é¡¯ç¤ºå‰å¹¾å¤§ç¸£å¸‚", min_value=1, max_value=10, value=3, step=1)

        # å¥—ç”¨ç¯©é¸å¾Œè³‡æ–™
        data = filtered.copy()

        # å…±ç”¨ï¼šæ’é™¤ SWI-å¯„åº«ï¼ˆä¾›é”äº¤ç‡/é…é€å€åŸŸ/é…é€è£è¼‰ä½¿ç”¨ï¼‰
        exclude_swi_mask = pd.Series(True, index=data.index)
        if ship_type_col in data.columns:
            exclude_swi_mask = data[ship_type_col] != "SWI-å¯„åº«"

        # =====================================================
        # â‘  å‡ºè²¨é¡å‹ç­†æ•¸çµ±è¨ˆï¼ˆå³å´æ–°å¢ï¼šéŠ…é‡é‡(kg)åˆè¨ˆï¼›ä¸”å°‡ã€ŒéŠ…é‡é‡(å™¸)ã€è¦–ç‚ºkgæ•¸å€¼ï¼‰
        # =====================================================
        st.subheader("â‘  å‡ºè²¨é¡å‹ç­†æ•¸çµ±è¨ˆ")

        if ship_type_col in data.columns:
            # ç­†æ•¸
            type_counts = (
                data[ship_type_col]
                .fillna("(ç©ºç™½)")
                .value_counts(dropna=False)
                .rename_axis("å‡ºè²¨é¡å‹")
                .reset_index(name="ç­†æ•¸")
            )
            total_rows = int(type_counts["ç­†æ•¸"].sum())

            # å°‡éŠ…é‡é‡æ¬„ä½è½‰ç‚ºæ•¸å€¼ï¼ˆå¯¦éš›å–®ä½=kgï¼‰
            if copper_ton_col in data.columns:
                data["_copper_kg"] = pd.to_numeric(data[copper_ton_col], errors="coerce")
                copper_sum = (
                    data.groupby(ship_type_col)["_copper_kg"]
                    .sum(min_count=1)
                    .reset_index()
                    .rename(columns={"_copper_kg": "éŠ…é‡é‡(kg)åˆè¨ˆ"})
                )
                merged = type_counts.merge(copper_sum, how="left", left_on="å‡ºè²¨é¡å‹", right_on=ship_type_col)
                if ship_type_col in merged.columns:
                    merged.drop(columns=[ship_type_col], inplace=True)
            else:
                merged = type_counts.copy()
                merged["éŠ…é‡é‡(kg)åˆè¨ˆ"] = None

            chart_choice = st.radio("åœ–è¡¨é¡å‹", ["é•·æ¢åœ–", "åœ“é¤…åœ–", "æŠ˜ç·šåœ–"], horizontal=True)

            c1, c2 = st.columns([1, 1])
            with c1:
                st.write(f"**åŠ ç¸½ç­†æ•¸ï¼š{total_rows:,}**")
                if "éŠ…é‡é‡(kg)åˆè¨ˆ" in merged.columns:
                    total_copper = pd.to_numeric(merged["éŠ…é‡é‡(kg)åˆè¨ˆ"], errors="coerce").sum()
                    st.write(f"**ç¸½éŠ…é‡é‡ (kg)ï¼š{total_copper:,.2f}**")
                st.dataframe(merged, use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰å‡ºè²¨é¡å‹çµ±è¨ˆ CSV",
                    data=merged.to_csv(index=False).encode("utf-8-sig"),
                    file_name="å‡ºè²¨é¡å‹_çµ±è¨ˆ.csv",
                    mime="text/csv",
                )
            with c2:
                if not type_counts.empty:
                    if chart_choice == "é•·æ¢åœ–":
                        fig = px.bar(type_counts, x="å‡ºè²¨é¡å‹", y="ç­†æ•¸")
                    elif chart_choice == "åœ“é¤…åœ–":
                        fig = px.pie(type_counts, names="å‡ºè²¨é¡å‹", values="ç­†æ•¸", hole=0)
                    else:  # æŠ˜ç·šåœ–
                        fig = px.line(type_counts, x="å‡ºè²¨é¡å‹", y="ç­†æ•¸", markers=True)
                    st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("æ‰¾ä¸åˆ°å‡ºè²¨é¡å‹æ¬„ä½ï¼Œè«‹åœ¨å´æ¬„é‡æ–°é¸æ“‡ã€‚")

        st.markdown("---")

        # =====================================================
        # â‘¡ é”äº¤ç‡ï¼ˆåƒ…æ¯”å°æ—¥æœŸï¼Œä¸å«æ™‚åˆ†ç§’ï¼›æ’é™¤ SWI-å¯„åº«ï¼‰
        # =====================================================
        st.subheader("â‘¡ é”äº¤ç‡ï¼ˆåƒ…æ¯”å°æ—¥æœŸï¼Œä¸å«æ™‚åˆ†ç§’ï¼‰")
        if due_date_col in data.columns and sign_date_col in data.columns:
            due_dt = to_dt(data[due_date_col])
            sign_dt = to_dt(data[sign_date_col])
            due_day = due_dt.dt.normalize()
            sign_day = sign_dt.dt.normalize()

            valid_mask = due_day.notna() & sign_day.notna() & exclude_swi_mask
            on_time = (sign_day <= due_day) & valid_mask

            total_valid = int(valid_mask.sum())
            on_time_count = int(on_time.sum())
            rate = (on_time_count / total_valid * 100.0) if total_valid > 0 else 0.0

            k1, k2, k3, k4 = st.columns(4)
            k1.metric("æœ‰æ•ˆç­†æ•¸ï¼ˆå…©æ—¥æœŸçš†æœ‰å€¼ï¼‰", f"{total_valid:,}")
            k2.metric("æº–æ™‚äº¤ä»˜ç­†æ•¸", f"{on_time_count:,}")
            k3.metric("é”äº¤ç‡", f"{rate:.2f}%")

            # æœªé”æ¨™ï¼ˆé²äº¤ï¼‰æ¸…å–® + å»¶é²å¤©æ•¸ + å¹³å‡å»¶é²å¤©æ•¸
            late_mask = valid_mask & (sign_day > due_day)
            delay_days = (sign_day - due_day).dt.days
            late_df = pd.DataFrame({
                "å®¢æˆ¶ç·¨è™Ÿ": data[cust_id_col] if cust_id_col in data.columns else None,
                "å®¢æˆ¶åç¨±": data[cust_name_col] if cust_name_col in data.columns else None,
                "æŒ‡å®šåˆ°è²¨æ—¥æœŸ": due_day.dt.strftime("%Y-%m-%d"),
                "å®¢æˆ¶ç°½æ”¶æ—¥æœŸ": sign_day.dt.strftime("%Y-%m-%d"),
                "å»¶é²å¤©æ•¸": delay_days,
            })[late_mask]

            avg_delay = float(late_df["å»¶é²å¤©æ•¸"].mean()) if not late_df.empty else 0.0
            k4.metric("å¹³å‡å»¶é²å¤©æ•¸", f"{avg_delay:.2f}")

            st.write("**æœªé”æ¨™æ¸…å–®**ï¼ˆå·²æ’é™¤å‡ºè²¨é¡å‹=SWI-å¯„åº«ï¼›åƒ…åˆ—ç°½æ”¶æ™šæ–¼æŒ‡å®šåˆ°è²¨è€…ï¼‰")
            st.dataframe(late_df, use_container_width=True)
            st.download_button(
                "ä¸‹è¼‰æœªé”æ¨™æ¸…å–® CSV",
                data=late_df.to_csv(index=False).encode("utf-8-sig"),
                file_name="æœªé”æ¨™æ¸…å–®.csv",
                mime="text/csv",
            )

            # ä¾å®¢æˆ¶åç¨±ï¼šæœªé”äº¤ç­†æ•¸èˆ‡æ¯”ä¾‹ï¼ˆåƒ…é¡¯ç¤ºæœªé”äº¤ > 0ï¼‰
            if cust_name_col in data.columns:
                tmp = pd.DataFrame({
                    "å®¢æˆ¶åç¨±": data[cust_name_col],
                    "æ˜¯å¦æœ‰æ•ˆ": valid_mask,
                    "æ˜¯å¦é²äº¤": late_mask,
                })
                grp = tmp.groupby("å®¢æˆ¶åç¨±")
                stats = grp["æ˜¯å¦æœ‰æ•ˆ"].sum().to_frame(name="æœ‰æ•ˆç­†æ•¸")
                stats["æœªé”äº¤ç­†æ•¸"] = grp["æ˜¯å¦é²äº¤"].sum()
                stats = stats[stats["æœªé”äº¤ç­†æ•¸"] > 0]
                stats["æœªé”äº¤æ¯”ä¾‹(%)"] = (stats["æœªé”äº¤ç­†æ•¸"] / stats["æœ‰æ•ˆç­†æ•¸"] * 100).round(2)
                stats = stats.reset_index().sort_values(["æœªé”äº¤ç­†æ•¸", "æœªé”äº¤æ¯”ä¾‹(%)"], ascending=[False, False])

                st.write("**ä¾å®¢æˆ¶åç¨±çµ±è¨ˆï¼šæœªé”äº¤ç­†æ•¸èˆ‡æ¯”ä¾‹ï¼ˆåƒ…é¡¯ç¤ºæœªé”äº¤>0ï¼›å·²æ’é™¤SWI-å¯„åº«ï¼‰**")
                st.dataframe(stats, use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰æœªé”äº¤çµ±è¨ˆï¼ˆå®¢æˆ¶ï¼‰ CSV",
                    data=stats.to_csv(index=False).encode("utf-8-sig"),
                    file_name="æœªé”äº¤çµ±è¨ˆ_ä¾å®¢æˆ¶.csv",
                    mime="text/csv",
                )
        else:
            st.warning("è«‹åœ¨å´æ¬„é¸å¥½ã€æŒ‡å®šåˆ°è²¨æ—¥æœŸã€èˆ‡ã€å®¢æˆ¶ç°½æ”¶æ—¥æœŸã€æ¬„ä½ã€‚")

        st.markdown("---")

        # =====================================================
        # â‘¢ é…é€å€åŸŸåˆ†æï¼ˆæ’é™¤ SWI-å¯„åº«ï¼‰
        # =====================================================
        st.subheader("â‘¢ é…é€å€åŸŸåˆ†æï¼ˆæ’é™¤ SWI-å¯„åº«ï¼‰")
        if address_col in data.columns:
            region_df = data[exclude_swi_mask].copy()
            region_df["ç¸£å¸‚"] = region_df[address_col].apply(extract_city)
            region_df["ç¸£å¸‚"] = region_df["ç¸£å¸‚"].fillna("(æœªçŸ¥)")

            # 3-1 å„ç¸£å¸‚é…é€ç­†æ•¸ + ç¸£å¸‚ä½”æ¯”
            city_counts = (
                region_df["ç¸£å¸‚"].value_counts(dropna=False)
                .rename_axis("ç¸£å¸‚").reset_index(name="ç­†æ•¸")
            )
            total_city = int(city_counts["ç­†æ•¸"].sum()) if not city_counts.empty else 0
            city_counts["ç¸£å¸‚ä½”æ¯”(%)"] = (
                (city_counts["ç­†æ•¸"] / total_city * 100).round(2) if total_city > 0 else 0
            )

            c1, c2 = st.columns([1, 1])
            with c1:
                st.write("**å„ç¸£å¸‚é…é€ç­†æ•¸**")
                st.dataframe(city_counts, use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰å„ç¸£å¸‚é…é€ç­†æ•¸ CSV",
                    data=city_counts.to_csv(index=False).encode("utf-8-sig"),
                    file_name="å„ç¸£å¸‚é…é€ç­†æ•¸.csv",
                    mime="text/csv",
                )
            with c2:
                if not city_counts.empty:
                    fig_city = px.bar(city_counts, x="ç¸£å¸‚", y="ç­†æ•¸")
                    st.plotly_chart(fig_city, use_container_width=True)

            st.markdown("â€”")

            # 3-2 å„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚ï¼ˆæ¯å®¢æˆ¶ TopNï¼‰+ å®¢æˆ¶å…§éƒ¨çš„ç¸£å¸‚ä½”æ¯”
            if cust_name_col in region_df.columns:
                cust_city = (
                    region_df.groupby([cust_name_col, "ç¸£å¸‚"]).size()
                    .reset_index(name="ç­†æ•¸")
                )
                cust_city["å®¢æˆ¶ç¸½ç­†æ•¸"] = cust_city.groupby(cust_name_col)["ç­†æ•¸"].transform("sum")
                cust_city["ç¸£å¸‚ä½”æ¯”(%)"] = (cust_city["ç­†æ•¸"] / cust_city["å®¢æˆ¶ç¸½ç­†æ•¸"] * 100).round(2)
                cust_city = cust_city.sort_values([cust_name_col, "ç­†æ•¸"], ascending=[True, False])
                top_table = cust_city.groupby(cust_name_col).head(topn)

                st.write(f"**å„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚ï¼ˆæ¯å®¢æˆ¶ Top {topn}ï¼‰**")
                st.dataframe(top_table.rename(columns={cust_name_col: "å®¢æˆ¶åç¨±"}), use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰å„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚ CSV",
                    data=top_table.to_csv(index=False).encode("utf-8-sig"),
                    file_name="å„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚_TopN.csv",
                    mime="text/csv",
                )
            else:
                st.info("æ‰¾ä¸åˆ°ã€å®¢æˆ¶åç¨±ã€æ¬„ä½ï¼Œç„¡æ³•ç”¢ç”Ÿå„å®¢æˆ¶å¸¸å‡ºè²¨ç¸£å¸‚çµ±è¨ˆã€‚")
        else:
            st.warning("è«‹åœ¨å´æ¬„é¸æ“‡æ­£ç¢ºçš„ã€åœ°å€ã€æ¬„ä½ã€‚")

        st.markdown("---")

# =====================================================
# â‘£ é…é€è£è¼‰åˆ†æï¼ˆå‡ºåº«å–®è™Ÿå‰13ç¢¼=åŒè»Šï¼›æ’é™¤ SWI-å¯„åº«ï¼‰
# =====================================================
        st.subheader("â‘£ é…é€è£è¼‰åˆ†æï¼ˆå‡ºåº«å–®è™Ÿå‰13ç¢¼=åŒè»Šï¼Œæ’é™¤ SWI-å¯„åº«ï¼‰")
            if ship_no_col in data.columns:
            load_df = data[exclude_swi_mask].copy()
        
            # ä»¥å‡ºåº«å–®è™Ÿå‰13ç¢¼å®šç¾©ã€Œè»Šæ¬¡ä»£ç¢¼ã€ï¼Œä½†æ¸…å–®ä»é¡¯ç¤ºå®Œæ•´å‡ºåº«å–®è™Ÿ
            load_df["è»Šæ¬¡ä»£ç¢¼"] = load_df[ship_no_col].astype(str).str[:13]
        
            # æ•¸å€¼è½‰æ›ï¼šå‡ºè²¨æ•¸é‡ã€éŠ…é‡é‡(kg)ï¼ˆåŸæ¬„åç‚ºã€ŒéŠ…é‡é‡(å™¸)ã€ä½†å¯¦éš›å–®ä½æ˜¯ kgï¼‰ã€æˆå“æ·¨/æ¯›é‡(å™¸)
            load_df["_qty_num"] = (
                pd.to_numeric(load_df[qty_col], errors="coerce")
                if (qty_col in load_df.columns) else pd.Series(dtype="float64", index=load_df.index)
            )
            load_df["_copper_kg"] = (
                pd.to_numeric(load_df[copper_ton_col], errors="coerce")
                if (copper_ton_col in load_df.columns) else pd.Series(dtype="float64", index=load_df.index)
            )
            load_df["_copper_ton"] = load_df["_copper_kg"] / 1000.0
        
            load_df["_fg_net_ton"] = (
                pd.to_numeric(load_df[fg_net_ton_col], errors="coerce")
                if (fg_net_ton_col in load_df.columns) else pd.Series(dtype="float64", index=load_df.index)
            )
            load_df["_fg_gross_ton"] = (
                pd.to_numeric(load_df[fg_gross_ton_col], errors="coerce")
                if (fg_gross_ton_col in load_df.columns) else pd.Series(dtype="float64", index=load_df.index)
            )
        
            # ==== æ˜ç´°æ¸…å–® ====
            # ä½¿ç”¨å®‰å…¨å‘½åèˆ‡å»é‡ï¼Œé¿å…æ¬„ä½é‡åé€ æˆå´©æ½°ï¼›å‡ºåº«å–®è™Ÿé¡¯ç¤ºå®Œæ•´å€¼
            wanted = [
                ("è»Šæ¬¡ä»£ç¢¼", "è»Šæ¬¡ä»£ç¢¼"),
                (ship_no_col, "å‡ºåº«å–®è™Ÿ"),        # é¡¯ç¤ºå®Œæ•´å€¼
                (do_col, "DOè™Ÿ"),
                (item_desc_col, "æ–™è™Ÿèªªæ˜"),
                (lot_col, "æ‰¹æ¬¡"),
                ("_qty_num", "å‡ºè²¨æ•¸é‡"),
                ("_copper_ton", "éŠ…é‡é‡(å™¸)"),   # ä»¥ kg è½‰å™¸é¡¯ç¤º
                ("_fg_net_ton", "æˆå“æ·¨é‡(å™¸)"),
                ("_fg_gross_ton", "æˆå“æ¯›é‡(å™¸)"),
            ]
            display_cols = {}
            used_names = set()
            for src, nice in wanted:
                # src å¯èƒ½æ˜¯å­—ä¸²æ¬„ä½åä¹Ÿå¯èƒ½æ˜¯è¨ˆç®—æ¬„ï¼ˆä¸Šé¢å·²æ”¾åˆ° load_dfï¼‰
                if isinstance(src, str) and (src in load_df.columns):
                    name = nice
                    i = 2
                    while name in used_names:
                        name = f"{nice} ({i})"
                        i += 1
                    display_cols[name] = load_df[src]
                    used_names.add(name)
        
            if display_cols:
                display_df = pd.DataFrame(display_cols)
        
                # æ•¸å€¼æ¬„å››æ¨äº”å…¥
                for c in ["å‡ºè²¨æ•¸é‡", "éŠ…é‡é‡(å™¸)", "æˆå“æ·¨é‡(å™¸)", "æˆå“æ¯›é‡(å™¸)"]:
                    if c in display_df.columns:
                        display_df[c] = pd.to_numeric(display_df[c], errors="coerce").round(3)
        
                # ä¾è»Šæ¬¡ä»£ç¢¼ã€å‡ºåº«å–®è™Ÿæ’åº
                sort_keys = [c for c in ["è»Šæ¬¡ä»£ç¢¼", "å‡ºåº«å–®è™Ÿ"] if c in display_df.columns]
                if sort_keys:
                    display_df = display_df.sort_values(by=sort_keys).reset_index(drop=True)
        
                st.write("**é…é€è£è¼‰æ¸…å–®ï¼ˆä¾è»Šæ¬¡ä»£ç¢¼åˆ†è»Šï¼‰**")
                st.dataframe(display_df, use_container_width=True)
                st.download_button(
                    "ä¸‹è¼‰é…é€è£è¼‰æ¸…å–® CSV",
                    data=display_df.to_csv(index=False).encode("utf-8-sig"),
                    file_name="é…é€è£è¼‰æ¸…å–®.csv",
                    mime="text/csv",
                )
            else:
                st.info("å·²æ’é™¤ SWI-å¯„åº«ï¼Œä½†ç›®å‰ç„¡å¯é¡¯ç¤ºæ¬„ä½ï¼Œè«‹åœ¨å´æ¬„ç¢ºèªæ¬„ä½å°æ‡‰ã€‚")
        
            # ==== è»Šæ¬¡å½™ç¸½ï¼ˆæ¯è»Šå°è¨ˆï¼‰ ====
            group = load_df.groupby("è»Šæ¬¡ä»£ç¢¼", dropna=False)
            agg_dict = {
                "å‡ºè²¨æ•¸é‡å°è¨ˆ": ("_qty_num", "sum"),
                "éŠ…é‡é‡(kg)_å°è¨ˆ": ("_copper_kg", "sum"),
                "æˆå“æ·¨é‡(å™¸)_å°è¨ˆ": ("_fg_net_ton", "sum"),
                "æˆå“æ¯›é‡(å™¸)_å°è¨ˆ": ("_fg_gross_ton", "sum"),
            }
            summary = group.agg(**agg_dict).reset_index()
        
            # è£œä¸ŠéŠ…é‡é‡(å™¸)_å°è¨ˆï¼ˆç”± kg è½‰å™¸ï¼‰
            if "éŠ…é‡é‡(kg)_å°è¨ˆ" in summary.columns:
                summary["éŠ…é‡é‡(å™¸)_å°è¨ˆ"] = (
                    pd.to_numeric(summary["éŠ…é‡é‡(kg)_å°è¨ˆ"], errors="coerce") / 1000.0
                ).round(3)
        
            # æ•¸å€¼æ¬„çµ±ä¸€å››æ¨äº”å…¥
            for c in ["å‡ºè²¨æ•¸é‡å°è¨ˆ", "éŠ…é‡é‡(kg)_å°è¨ˆ", "æˆå“æ·¨é‡(å™¸)_å°è¨ˆ", "æˆå“æ¯›é‡(å™¸)_å°è¨ˆ", "éŠ…é‡é‡(å™¸)_å°è¨ˆ"]:
                if c in summary.columns:
                    summary[c] = pd.to_numeric(summary[c], errors="coerce").round(3)
        
            st.write("**è»Šæ¬¡å½™ç¸½ï¼ˆæ¯è»Šå°è¨ˆï¼‰**")
            st.dataframe(summary, use_container_width=True)
            st.download_button(
                "ä¸‹è¼‰è»Šæ¬¡å½™ç¸½ CSV",
                data=summary.to_csv(index=False).encode("utf-8-sig"),
                file_name="è»Šæ¬¡å½™ç¸½.csv",
                mime="text/csv",
            )
        
            # ==== KPIï¼šå¹³å‡è»Šå­è¼‰é‡(å™¸) ====
            # åƒ…è¨ˆç®—éŠ…é‡é‡(å™¸)_å°è¨ˆ > 0 çš„è»Šæ¬¡
            if "éŠ…é‡é‡(å™¸)_å°è¨ˆ" in summary.columns:
                valid = summary[pd.to_numeric(summary["éŠ…é‡é‡(å™¸)_å°è¨ˆ"], errors="coerce") > 0]
                avg_load = float(valid["éŠ…é‡é‡(å™¸)_å°è¨ˆ"].mean()) if not valid.empty else 0.0
                k1, k2 = st.columns(2)
                k1.metric("ç´å…¥è¨ˆç®—è»Šæ¬¡", f"{len(valid):,}")
                k2.metric("å¹³å‡è»Šå­è¼‰é‡(å™¸)", f"{avg_load:.2f}")
        else:
            st.info("è«‹åœ¨å´æ¬„æŒ‡å®šã€å‡ºåº«å–®è™Ÿã€æ¬„ä½ï¼Œä»¥é€²è¡Œè£è¼‰åˆ†æã€‚")
        

        # =====================================================
        # è‡ªè¨‚æ¬„ä½ â†’ èšåˆï¼ˆè¨ˆç®—åœ¨æ­¤ï¼Œä½†é¡¯ç¤ºæ¬åˆ° tab_aggï¼‰
        # =====================================================
        with st.sidebar:
            st.subheader("ğŸ§® æ–°å¢è‡ªè¨‚æ¬„ä½")
            st.caption("ä½¿ç”¨ç¾æœ‰æ¬„ä½åšè¨ˆç®—ï¼Œä¾‹å¦‚ï¼š`éŠ·å”®é¡ - æˆæœ¬` æˆ– `æ•¸é‡ * å–®åƒ¹`")
            new_col_name = st.text_input("æ–°æ¬„ä½åç¨±", value="")
            formula = st.text_input("è¼¸å…¥å…¬å¼ï¼ˆç­‰è™Ÿå³é‚Šï¼‰", placeholder="ä¾‹å¦‚ï¼šæ•¸é‡ * å–®åƒ¹")

        data_for_calc = data.copy()
        if new_col_name and formula:
            try:
                data_for_calc[new_col_name] = pd.eval(
                    formula, engine="python", local_dict=data_for_calc.to_dict("series")
                )
                st.success(f"å·²æ–°å¢æ¬„ä½ï¼š{new_col_name}")
            except Exception as e:
                st.error(f"å…¬å¼éŒ¯èª¤ï¼š{e}")

        with st.sidebar:
            st.subheader("ğŸ“¦ èšåˆå½™æ•´ï¼ˆçµæœé¡¯ç¤ºåœ¨ã€ğŸ“¦ èšåˆçµæœã€åˆ†é ï¼‰")
            group_cols = st.multiselect("ç¾¤çµ„æ¬„ä½ï¼ˆå¯å¤šé¸ï¼‰", list(data_for_calc.columns))
            numeric_cols = data_for_calc.select_dtypes(include="number").columns.tolist()
            agg_col = st.selectbox("èšåˆæ¬„ä½", numeric_cols or ["ï¼ˆç„¡æ•¸å€¼æ¬„ä½ï¼‰"])
            agg_fn = st.selectbox("èšåˆå‡½æ•¸", ["sum", "mean", "max", "min", "count"])

        # åœ¨åˆ†æåˆ†é ä¸­å…ˆç®—å¥½ï¼Œç¨å¾Œåœ¨ tab_agg é¡¯ç¤º
        agg_df = data_for_calc.copy()
        if group_cols and (agg_col in data_for_calc.columns):
            agg_df = (
                agg_df.groupby(group_cols, dropna=False)[agg_col]
                .agg(agg_fn)
                .reset_index()
                .rename(columns={agg_col: f"{agg_fn}_{agg_col}"})
            )

        # ---------- è¦–è¦ºåŒ–ï¼ˆæ²¿ç”¨èšåˆçµæœï¼‰ ----------
        st.subheader("ğŸ“ˆ è¦–è¦ºåŒ–ï¼ˆä½¿ç”¨ç›®å‰èšåˆçµæœï¼‰")
        num_cols = agg_df.select_dtypes(include="number").columns.tolist()
        cat_cols = [c for c in agg_df.columns if c not in num_cols]
        if len(agg_df.columns) >= 2 and num_cols:
            x = st.selectbox("X è»¸", cat_cols + num_cols)
            y = st.selectbox("Y è»¸ï¼ˆæ•¸å€¼ï¼‰", num_cols)
            chart_type = st.selectbox("åœ–è¡¨é¡å‹", ["bar", "line", "scatter"])
            if chart_type == "bar":
                fig = px.bar(agg_df, x=x, y=y)
            elif chart_type == "line":
                fig = px.line(agg_df, x=x, y=y)
            else:
                fig = px.scatter(agg_df, x=x, y=y)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ç›®å‰æ²’æœ‰è¶³å¤ æ¬„ä½å¯ç•«åœ–ï¼Œè«‹å…ˆåšèšåˆæˆ–æ–°å¢æ•¸å€¼æ¬„ä½ã€‚")

        # æŠŠ agg_df æš´éœ²åˆ°å¤–å±¤ä¾› tab_agg ä½¿ç”¨
        st.session_state["_agg_df"] = agg_df
        st.session_state["_data_filtered"] = data

    # ============= èšåˆçµæœåˆ†é ï¼ˆé¡¯ç¤ºç”¨ï¼‰ =============
    with tab_agg:
        st.subheader("è™•ç†å¾Œè³‡æ–™ï¼ˆèšåˆçµæœï¼‰")
        agg_df = st.session_state.get("_agg_df", pd.DataFrame())
        data = st.session_state.get("_data_filtered", df)
        st.dataframe(agg_df, use_container_width=True)

        st.subheader("â¬‡ï¸ ä¸‹è¼‰")
        st.download_button(
            "ä¸‹è¼‰èšåˆçµæœ CSV",
            data=agg_df.to_csv(index=False).encode("utf-8-sig"),
            file_name="èšåˆçµæœ.csv",
            mime="text/csv",
        )

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            data.to_excel(writer, index=False, sheet_name="ç¯©é¸å¾ŒåŸå§‹")
            agg_df.to_excel(writer, index=False, sheet_name="èšåˆçµæœ")
        st.download_button(
            "ä¸‹è¼‰ Excel",
            data=output.getvalue(),
            file_name="TMS_å‡ºè²¨é…é€åˆ†æ.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

else:
    st.info("è«‹å…ˆåœ¨ä¸Šæ–¹ä¸Šå‚³ Excel æˆ– CSV æª”ã€‚")


