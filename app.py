import io
import re
from typing import Dict, Optional, Tuple
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

# ä¾è³´æª¢æŸ¥
try:
    import openpyxl
    EXCEL_AVAILABLE = True
except ImportError:
    EXCEL_AVAILABLE = False

# ========================
# é é¢è¨­å®šèˆ‡ CSS æ¨£å¼
# ========================

st.set_page_config(
    page_title="TMSå‡ºè²¨é…é€æ•¸æ“šåˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ç´ é›…è‰²å½©é…ç½®
ELEGANT_COLORS = {
    'primary': '#6c7b7f',      # å„ªé›…ç°è—
    'secondary': '#a8b5b8',    # æ·ºç°è—
    'success': '#8fbc8f',      # æŸ”å’Œç¶ 
    'warning': '#daa520',      # å¤é‡‘è‰²
    'danger': '#cd5c5c',       # å°åº¦ç´…
    'light_gray': '#f5f7fa',   # æ·ºç°
    'dark_gray': '#2c3e50'     # æ·±ç°
}

# å½©è‰²èª¿è‰²æ¿
COLORFUL_PALETTE = [
    '#DDA0DD',  # æ·¡ç´«è‰²
    '#87CEEB',  # æ·¡è—è‰²
    '#98FB98',  # æ·¡ç¶ è‰²
    '#F0E68C',  # æ·¡é‡‘è‰²
    '#FFB6C1',  # æ·¡ç²‰è‰²
    '#DEB887',  # æ·¡æ£•è‰²
    '#E0E0E0',  # æ·¡ç°è‰²
    '#FFA07A',  # æ·¡æ©™è‰²
    '#20B2AA',  # æ·¡é’è‰²
    '#D8BFD8',  # è–Šè‰²
    '#AFEEEE',  # æ·¡è—ç¶ è‰²
    '#F5DEB3'   # å°éº¥è‰²
]

def format_number_with_comma(value, decimal_places=0):
    """æ ¼å¼åŒ–æ•¸å­—ï¼šåƒåˆ†ä½ + é å³å°é½Š"""
    if pd.isna(value):
        return ""
    try:
        if decimal_places == 0:
            return f"{int(value):,}"
        else:
            return f"{float(value):,.{decimal_places}f}"
    except:
        return str(value)

# è‡ªå®šç¾© CSS æ¨£å¼
st.markdown(f"""
<style>
    .main-header {{
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(90deg, {ELEGANT_COLORS['primary']}, {ELEGANT_COLORS['secondary']});
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
        font-size: 2.5rem;
        font-weight: bold;
        margin-bottom: 1rem;
    }}
    
    .metric-container {{
        background: {ELEGANT_COLORS['light_gray']};
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.08);
        border-left: 4px solid {ELEGANT_COLORS['primary']};
        margin: 0.5rem 0;
    }}
    
    .section-header {{
        color: {ELEGANT_COLORS['dark_gray']};
        border-bottom: 2px solid {ELEGANT_COLORS['secondary']};
        padding-bottom: 0.5rem;
        margin: 1.5rem 0 1rem 0;
    }}
</style>
""", unsafe_allow_html=True)

# ä¸»æ¨™é¡Œ
st.markdown('<h1 class="main-header">ğŸ“Š TMSå‡ºè²¨é…é€æ•¸æ“šåˆ†æ</h1>', unsafe_allow_html=True)
st.markdown("""
<div style="text-align: center; color: #7f8c8d; margin-bottom: 2rem;">
    <strong>æ™ºèƒ½åŒ–æ•¸æ“šåˆ†æå¹³å°</strong> | ä¸Šå‚³ Excel/CSV â†’ å‡ºè²¨é¡å‹åˆ†æ â†’ é…é€é”äº¤ç‡ â†’ å€åŸŸåˆ†æ â†’ è£è¼‰åˆ†æ
</div>
""", unsafe_allow_html=True)

# ========================
# å·¥å…·å‡½å¼å„ªåŒ–
# ========================

@st.cache_data(show_spinner="æ­£åœ¨è¼‰å…¥æª”æ¡ˆ...")
def load_data(file_buffer: io.BytesIO, file_type: str) -> pd.DataFrame:
    """é«˜æ•ˆèƒ½æª”æ¡ˆè¼‰å…¥èˆ‡å¿«å–"""
    try:
        if file_type == "csv":
            encodings = ['utf-8', 'utf-8-sig', 'big5', 'gbk']
            for encoding in encodings:
                try:
                    file_buffer.seek(0)
                    return pd.read_csv(file_buffer, encoding=encoding)
                except UnicodeDecodeError:
                    continue
            file_buffer.seek(0)
            return pd.read_csv(file_buffer, encoding='utf-8', errors='ignore')
        elif file_type in ["xlsx", "xls"]:
            if not EXCEL_AVAILABLE:
                st.error("éœ€è¦å®‰è£ openpyxl ä¾†è™•ç† Excel æª”æ¡ˆ")
                return pd.DataFrame()
            file_buffer.seek(0)
            return pd.read_excel(file_buffer, engine="openpyxl")
    except Exception as e:
        st.error(f"æª”æ¡ˆè¼‰å…¥å¤±æ•—: {str(e)}")
        return pd.DataFrame()
    
    st.error("ä¸æ”¯æ´çš„æª”æ¡ˆé¡å‹")
    return pd.DataFrame()

def smart_column_detector(df_cols: list) -> Dict[str, Optional[str]]:
    """æ™ºèƒ½æ¬„ä½åµæ¸¬å™¨"""
    def find_best_match(keywords: list, priority_keywords: list = None) -> Optional[str]:
        if priority_keywords:
            for kw in priority_keywords:
                for col in df_cols:
                    if kw.lower() in str(col).lower():
                        return col
        
        for kw in keywords:
            for col in df_cols:
                if kw.lower() in str(col).lower():
                    return col
        return None

    return {
        "ship_type": find_best_match(["å‡ºè²¨ç”³è«‹é¡å‹", "å‡ºè²¨é¡å‹", "é…é€é¡å‹", "é¡å‹"], ["å‡ºè²¨ç”³è«‹é¡å‹"]),
        "due_date": find_best_match(["æŒ‡å®šåˆ°è²¨æ—¥æœŸ", "åˆ°è²¨æ—¥æœŸ", "æŒ‡å®šåˆ°è²¨"], ["æŒ‡å®šåˆ°è²¨æ—¥æœŸ"]),
        "sign_date": find_best_match(["å®¢æˆ¶ç°½æ”¶æ—¥æœŸ", "ç°½æ”¶æ—¥æœŸ", "ç°½æ”¶æ—¥"], ["å®¢æˆ¶ç°½æ”¶æ—¥æœŸ"]),
        "cust_id": find_best_match(["å®¢æˆ¶ç·¨è™Ÿ", "å®¢æˆ¶ä»£è™Ÿ", "å®¢ç·¨"], ["å®¢æˆ¶ç·¨è™Ÿ"]),
        "cust_name": find_best_match(["å®¢æˆ¶åç¨±", "å®¢å", "å®¢æˆ¶"], ["å®¢æˆ¶åç¨±"]),
        "address": find_best_match(["åœ°å€", "æ”¶è²¨åœ°å€", "é€è²¨åœ°å€"], ["åœ°å€"]),
        "copper_ton": find_best_match(["éŠ…é‡é‡(å™¸)", "éŠ…é‡é‡", "éŠ…å™¸"], ["éŠ…é‡é‡(å™¸)"]),
        "qty": find_best_match(["å‡ºè²¨æ•¸é‡", "æ•¸é‡", "å‡ºè²¨é‡"], ["å‡ºè²¨æ•¸é‡"]),
        "ship_no": find_best_match(["å‡ºåº«å–®è™Ÿ", "å‡ºåº«å–®", "å‡ºåº«ç·¨è™Ÿ"], ["å‡ºåº«å–®è™Ÿ"]),
        "do_no": find_best_match(["DOè™Ÿ", "DO", "å‡ºè²¨å–®è™Ÿ"], ["DOè™Ÿ"]),
        "item_desc": find_best_match(["æ–™è™Ÿèªªæ˜", "å“å", "å“åè¦æ ¼"], ["æ–™è™Ÿèªªæ˜"]),
        "lot_no": find_best_match(["æ‰¹æ¬¡", "æ‰¹è™Ÿ", "Lot"], ["æ‰¹æ¬¡"]),
        "fg_net_ton": find_best_match(["æˆå“æ·¨é‡(å™¸)", "æ·¨é‡(å™¸)", "æ·¨é‡"], ["æˆå“æ·¨é‡(å™¸)"]),
        "fg_gross_ton": find_best_match(["æˆå“æ¯›é‡(å™¸)", "æ¯›é‡(å™¸)", "æ¯›é‡"], ["æˆå“æ¯›é‡(å™¸)"]),
        "status": find_best_match(["é€šçŸ¥å–®é …æ¬¡ç‹€æ…‹", "é …æ¬¡ç‹€æ…‹", "ç‹€æ…‹"], ["é€šçŸ¥å–®é …æ¬¡ç‹€æ…‹"]),
    }

def safe_datetime_convert(series: pd.Series) -> pd.Series:
    """å®‰å…¨çš„æ—¥æœŸæ™‚é–“è½‰æ›"""
    return pd.to_datetime(series, errors="coerce")

def enhanced_city_extraction(address: str) -> Optional[str]:
    """å¢å¼·ç‰ˆå°ç£ç¸£å¸‚æ“·å–"""
    if pd.isna(address) or not address:
        return None
    
    normalized_addr = str(address).strip().replace("è‡º", "å°")
    taiwan_cities = [
        "å°åŒ—å¸‚", "æ–°åŒ—å¸‚", "æ¡ƒåœ’å¸‚", "å°ä¸­å¸‚", "å°å—å¸‚", "é«˜é›„å¸‚",
        "åŸºéš†å¸‚", "æ–°ç«¹å¸‚", "æ–°ç«¹ç¸£", "è‹—æ —ç¸£", "å½°åŒ–ç¸£", "å—æŠ•ç¸£",
        "é›²æ—ç¸£", "å˜‰ç¾©å¸‚", "å˜‰ç¾©ç¸£", "å±æ±ç¸£", "å®œè˜­ç¸£", "èŠ±è“®ç¸£",
        "å°æ±ç¸£", "æ¾æ¹–ç¸£", "é‡‘é–€ç¸£", "é€£æ±Ÿç¸£"
    ]
    
    for city in taiwan_cities:
        if city in normalized_addr:
            return city
    return None

def create_enhanced_metric_card(title: str, value: str, delta: str = None, delta_color: str = "normal"):
    """å»ºç«‹å¢å¼·ç‰ˆæŒ‡æ¨™å¡ç‰‡"""
    delta_html = ""
    if delta:
        color = {"normal": "#666", "positive": ELEGANT_COLORS['success'], "negative": ELEGANT_COLORS['danger']}.get(delta_color, "#666")
        delta_html = f'<div style="color: {color}; font-size: 0.9rem; margin-top: 0.5rem;">{delta}</div>'
    
    st.markdown(f"""
    <div class="metric-container">
        <div style="color: #666; font-size: 0.9rem; margin-bottom: 0.3rem;">{title}</div>
        <div style="font-size: 2rem; font-weight: bold; color: {ELEGANT_COLORS['dark_gray']};">{value}</div>
        {delta_html}
    </div>
    """, unsafe_allow_html=True)

# ========================
# æ ¸å¿ƒåˆ†æå‡½å¼
# ========================

def enhanced_shipment_analysis(df: pd.DataFrame, col_map: Dict[str, Optional[str]]) -> None:
    """å¢å¼·ç‰ˆå‡ºè²¨é¡å‹åˆ†æ"""
    st.markdown('<h2 class="section-header">â‘  å‡ºè²¨é¡å‹ç­†æ•¸èˆ‡é‡é‡çµ±è¨ˆ</h2>', unsafe_allow_html=True)
    
    ship_type_col = col_map.get("ship_type")
    copper_ton_col = col_map.get("copper_ton")
    
    if not ship_type_col or ship_type_col not in df.columns:
        st.error("âš ï¸ æ‰¾ä¸åˆ°ã€å‡ºè²¨ç”³è«‹é¡å‹ã€æ¬„ä½")
        return
    
    # è™•ç†å‡ºè²¨é¡å‹çµ±è¨ˆ
    df_work = df.copy()
    df_work[ship_type_col] = df_work[ship_type_col].fillna("(ç©ºç™½)")
    
    type_stats = df_work[ship_type_col].value_counts().reset_index()
    type_stats.columns = ["å‡ºè²¨é¡å‹", "ç­†æ•¸"]
    
    # è¨ˆç®—éŠ…é‡é‡çµ±è¨ˆ
    final_stats = type_stats.copy()
    if copper_ton_col and copper_ton_col in df.columns:
        df_work["_copper_numeric"] = pd.to_numeric(df_work[copper_ton_col], errors="coerce")
        
        copper_summary = []
        for ship_type in type_stats["å‡ºè²¨é¡å‹"]:
            mask = df_work[ship_type_col] == ship_type
            copper_sum = df_work[mask]["_copper_numeric"].sum()
            copper_summary.append(copper_sum / 1000.0)  # è½‰ç‚ºå™¸
        
        final_stats["éŠ…é‡é‡(å™¸)åˆè¨ˆ"] = copper_summary
    else:
        final_stats["éŠ…é‡é‡(å™¸)åˆè¨ˆ"] = None
    
    # è¨ˆç®—ç™¾åˆ†æ¯”
    total_records = final_stats["ç­†æ•¸"].sum()
    final_stats["ä½”æ¯”(%)"] = (final_stats["ç­†æ•¸"] / total_records * 100).round(2)
    
    # é¡¯ç¤ºé—œéµæŒ‡æ¨™
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        create_enhanced_metric_card("ç¸½è³‡æ–™ç­†æ•¸", f"{total_records:,}")
    with col2:
        unique_types = len(final_stats)
        create_enhanced_metric_card("å‡ºè²¨é¡å‹æ•¸", f"{unique_types}")
    with col3:
        total_copper = final_stats["éŠ…é‡é‡(å™¸)åˆè¨ˆ"].sum() if "éŠ…é‡é‡(å™¸)åˆè¨ˆ" in final_stats.columns and final_stats["éŠ…é‡é‡(å™¸)åˆè¨ˆ"].notna().any() else 0
        create_enhanced_metric_card("ç¸½éŠ…é‡é‡(å™¸)", f"{total_copper:,.3f}")
    with col4:
        avg_per_record = total_copper / total_records if total_records > 0 else 0
        create_enhanced_metric_card("å¹³å‡æ¯ç­†é‡é‡(å™¸)", f"{avg_per_record:.3f}")
    
    # é¡¯ç¤ºè©³ç´°çµ±è¨ˆè¡¨æ ¼èˆ‡åœ–è¡¨
    tab1, tab2 = st.tabs(["ğŸ“‹ è©³ç´°çµ±è¨ˆ", "ğŸ“Š è¦–è¦ºåŒ–åœ–è¡¨"])
    
    with tab1:
        st.dataframe(final_stats, use_container_width=True, height=400)
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰çµ±è¨ˆè¡¨ (CSV)",
                data=final_stats.to_csv(index=False).encode("utf-8-sig"),
                file_name="å‡ºè²¨é¡å‹çµ±è¨ˆ.csv",
                mime="text/csv",
            )
    
    with tab2:
        chart_col1, chart_col2 = st.columns(2)
        
        with chart_col1:
            chart_type = st.selectbox("åœ–è¡¨é¡å‹", ["é•·æ¢åœ–", "åœ“é¤…åœ–", "ç’°å½¢åœ–", "æ°´å¹³é•·æ¢åœ–"], key="chart_type_1")
            
            # ç´ é›…è‰²å½©é…ç½®
            elegant_palette = ['#6c7b7f', '#a8b5b8', '#95a5a6', '#7f8c8d', '#bdc3c7', '#ecf0f1']
            
            if chart_type == "é•·æ¢åœ–":
                fig = px.bar(final_stats, x="å‡ºè²¨é¡å‹", y="ç­†æ•¸", title="å‡ºè²¨é¡å‹ç­†æ•¸åˆ†ä½ˆ")
                fig.update_traces(marker_color=ELEGANT_COLORS['primary'])
                fig.update_layout(xaxis_tickangle=-45)
            elif chart_type == "æ°´å¹³é•·æ¢åœ–":
                fig = px.bar(final_stats, x="ç­†æ•¸", y="å‡ºè²¨é¡å‹", orientation='h', title="å‡ºè²¨é¡å‹ç­†æ•¸åˆ†ä½ˆ")
                fig.update_traces(marker_color=ELEGANT_COLORS['secondary'])
            elif chart_type == "åœ“é¤…åœ–":
                fig = px.pie(final_stats, names="å‡ºè²¨é¡å‹", values="ç­†æ•¸", title="å‡ºè²¨é¡å‹ä½”æ¯”åˆ†ä½ˆ", color_discrete_sequence=elegant_palette)
                fig.update_traces(textposition='inside', textinfo='percent+label')
            else:  # ç’°å½¢åœ–
                fig = px.pie(final_stats, names="å‡ºè²¨é¡å‹", values="ç­†æ•¸", title="å‡ºè²¨é¡å‹ä½”æ¯”åˆ†ä½ˆ", hole=0.4, color_discrete_sequence=elegant_palette)
                fig.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)
        
        with chart_col2:
            if "éŠ…é‡é‡(å™¸)åˆè¨ˆ" in final_stats.columns and final_stats["éŠ…é‡é‡(å™¸)åˆè¨ˆ"].notna().any():
                fig_copper = px.treemap(
                    final_stats[final_stats["éŠ…é‡é‡(å™¸)åˆè¨ˆ"].notna()],
                    path=["å‡ºè²¨é¡å‹"],
                    values="éŠ…é‡é‡(å™¸)åˆè¨ˆ",
                    title="éŠ…é‡é‡åˆ†ä½ˆæ¨¹ç‹€åœ–",
                    color_discrete_sequence=COLORFUL_PALETTE
                )
                st.plotly_chart(fig_copper, use_container_width=True)
            else:
                st.info("ç„¡éŠ…é‡é‡æ•¸æ“šå¯ä¾›åˆ†æ")

def enhanced_delivery_performance(df: pd.DataFrame, col_map: Dict[str, Optional[str]], exclude_swi_mask: pd.Series) -> None:
    """å¢å¼·ç‰ˆé…é€é”äº¤ç‡åˆ†æ"""
    st.markdown('<h2 class="section-header">â‘¡ é…é€é”äº¤ç‡åˆ†æ</h2>', unsafe_allow_html=True)
    
    due_date_col = col_map.get("due_date")
    sign_date_col = col_map.get("sign_date")
    cust_name_col = col_map.get("cust_name")
    
    if not all([due_date_col, sign_date_col]) or not all([col in df.columns for col in [due_date_col, sign_date_col]]):
        st.error("âš ï¸ æ‰¾ä¸åˆ°å¿…è¦çš„æ—¥æœŸæ¬„ä½")
        return
    
    # æ—¥æœŸè™•ç†
    due_day = safe_datetime_convert(df[due_date_col]).dt.normalize()
    sign_day = safe_datetime_convert(df[sign_date_col]).dt.normalize()
    
    # æœ‰æ•ˆæ€§æª¢æŸ¥
    valid_mask = due_day.notna() & sign_day.notna() & exclude_swi_mask
    on_time_mask = (sign_day <= due_day) & valid_mask
    late_mask = valid_mask & (sign_day > due_day)
    
    # çµ±è¨ˆè¨ˆç®—
    total_valid = int(valid_mask.sum())
    on_time_count = int(on_time_mask.sum())
    late_count = int(late_mask.sum())
    
    if total_valid == 0:
        st.warning("ç„¡æœ‰æ•ˆçš„é”äº¤åˆ†ææ•¸æ“š")
        return
    
    delivery_rate = on_time_count / total_valid * 100
    delay_days = (sign_day - due_day).dt.days
    avg_delay = delay_days[late_mask].mean() if late_count > 0 else 0.0
    max_delay = delay_days[late_mask].max() if late_count > 0 else 0
    
    # é—œéµæŒ‡æ¨™å±•ç¤º
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        create_enhanced_metric_card("æœ‰æ•ˆç­†æ•¸", f"{total_valid:,}")
    with col2:
        create_enhanced_metric_card("æº–æ™‚äº¤ä»˜", f"{on_time_count:,}", f"({delivery_rate:.1f}%)", "positive")
    with col3:
        create_enhanced_metric_card("å»¶é²äº¤ä»˜", f"{late_count:,}", f"({100-delivery_rate:.1f}%)", "negative")
    with col4:
        status = "å„ªç•°" if delivery_rate >= 95 else "è‰¯å¥½" if delivery_rate >= 90 else "éœ€æ”¹å–„"
        color = "positive" if delivery_rate >= 95 else "normal" if delivery_rate >= 90 else "negative"
        create_enhanced_metric_card("é”äº¤ç‡", f"{delivery_rate:.2f}%", status, color)
    with col5:
        create_enhanced_metric_card("å¹³å‡å»¶é²", f"{avg_delay:.1f}å¤©", f"æœ€å¤§: {max_delay}å¤©" if max_delay > 0 else "")
    
    # è©³ç´°åˆ†æ
    analysis_tab1, analysis_tab2, analysis_tab3 = st.tabs(["ğŸšš æœªé”æ¨™æ˜ç´°", "ğŸ“ˆ é”äº¤è¶¨å‹¢", "ğŸ‘¥ å®¢æˆ¶è¡¨ç¾"])
    
    with analysis_tab1:
        if late_count > 0:
            late_indices = df.index[late_mask]
            late_details = pd.DataFrame({
                "æŒ‡å®šåˆ°è²¨æ—¥æœŸ": [due_day.loc[i].strftime("%Y-%m-%d") if pd.notna(due_day.loc[i]) else "" for i in late_indices],
                "å®¢æˆ¶ç°½æ”¶æ—¥æœŸ": [sign_day.loc[i].strftime("%Y-%m-%d") if pd.notna(sign_day.loc[i]) else "" for i in late_indices],
                "å»¶é²å¤©æ•¸": [delay_days.loc[i] if pd.notna(delay_days.loc[i]) else 0 for i in late_indices]
            })
            
            if col_map.get("cust_name") and col_map["cust_name"] in df.columns:
                late_details["å®¢æˆ¶åç¨±"] = [df.loc[i, col_map["cust_name"]] for i in late_indices]
            
            # å»¶é²ç¨‹åº¦åˆ†é¡
            late_details["å»¶é²ç¨‹åº¦"] = pd.cut(
                late_details["å»¶é²å¤©æ•¸"],
                bins=[-1, 0, 3, 7, 30, 999],
                labels=["æº–æ™‚", "è¼•å¾®å»¶é²(1-3å¤©)", "ä¸­åº¦å»¶é²(4-7å¤©)", "é‡åº¦å»¶é²(8-30å¤©)", "åš´é‡å»¶é²(>30å¤©)"]
            )
            
            late_details = late_details.sort_values("å»¶é²å¤©æ•¸", ascending=False)
            
            # æ ¼å¼åŒ–å»¶é²å¤©æ•¸é¡¯ç¤º
            display_late_details = late_details.copy()
            display_late_details["å»¶é²å¤©æ•¸"] = display_late_details["å»¶é²å¤©æ•¸"].apply(lambda x: format_number_with_comma(x))
            
            st.dataframe(display_late_details, use_container_width=True, height=400)
            
            # å»¶é²åˆ†ä½ˆåœ– - å½©è‰²ç‰ˆ
            delay_dist = late_details["å»¶é²ç¨‹åº¦"].value_counts()
            fig_delay = px.bar(
                x=delay_dist.index, 
                y=delay_dist.values,
                title="å»¶é²ç¨‹åº¦åˆ†ä½ˆ",
                labels={"x": "å»¶é²ç¨‹åº¦", "y": "ç­†æ•¸"},
                color_discrete_sequence=COLORFUL_PALETTE
            )
            st.plotly_chart(fig_delay, use_container_width=True)
            
            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰æœªé”æ¨™æ˜ç´°",
                data=late_details.to_csv(index=False).encode("utf-8-sig"),
                file_name="æœªé”æ¨™æ˜ç´°.csv",
                mime="text/csv",
            )
        else:
            st.success("ğŸ‰ æ­å–œï¼æ‰€æœ‰å‡ºè²¨éƒ½æº–æ™‚é”äº¤ï¼")
    
    with analysis_tab2:
        if total_valid >= 7:
            # å»ºç«‹è¶¨å‹¢æ•¸æ“š
            valid_indices = df.index[valid_mask]
            trend_data = []
            
            for idx in valid_indices:
                if pd.notna(due_day.loc[idx]):
                    trend_data.append({
                        "åˆ°è²¨æ—¥æœŸ": due_day.loc[idx].date(),
                        "æº–æ™‚": 1 if on_time_mask.loc[idx] else 0
                    })
            
            if trend_data:
                trend_df = pd.DataFrame(trend_data)
                daily_trend = trend_df.groupby("åˆ°è²¨æ—¥æœŸ").agg({
                    "æº–æ™‚": ["count", "sum"]
                }).reset_index()
                daily_trend.columns = ["åˆ°è²¨æ—¥æœŸ", "ç¸½ç­†æ•¸", "æº–æ™‚ç­†æ•¸"]
                daily_trend["é”äº¤ç‡(%)"] = (daily_trend["æº–æ™‚ç­†æ•¸"] / daily_trend["ç¸½ç­†æ•¸"] * 100).round(2)
                
                fig_trend = px.line(
                    daily_trend, 
                    x="åˆ°è²¨æ—¥æœŸ", 
                    y="é”äº¤ç‡(%)",
                    title="æ¯æ—¥é”äº¤ç‡è¶¨å‹¢",
                    markers=True,
                    color_discrete_sequence=COLORFUL_PALETTE
                )
                fig_trend.update_traces(line_color=COLORFUL_PALETTE[0], marker_color=COLORFUL_PALETTE[1])
                fig_trend.add_hline(y=95, line_dash="dash", line_color=COLORFUL_PALETTE[2], annotation_text="ç›®æ¨™ç·š(95%)")
                fig_trend.add_hline(y=90, line_dash="dash", line_color=COLORFUL_PALETTE[3], annotation_text="è­¦æˆ’ç·š(90%)")
                
                st.plotly_chart(fig_trend, use_container_width=True)
        else:
            st.info("æ•¸æ“šé‡ä¸è¶³ï¼Œç„¡æ³•åˆ†æè¶¨å‹¢ï¼ˆéœ€è‡³å°‘7ç­†è¨˜éŒ„ï¼‰")
    
    with analysis_tab3:
        if cust_name_col and cust_name_col in df.columns:
            # å®¢æˆ¶è¡¨ç¾åˆ†æ
            valid_indices = df.index[valid_mask]
            customer_data = []
            
            for idx in valid_indices:
                customer_data.append({
                    "å®¢æˆ¶åç¨±": df.loc[idx, cust_name_col],
                    "æº–æ™‚": 1 if on_time_mask.loc[idx] else 0,
                    "ç¸½è¨ˆ": 1
                })
            
            if customer_data:
                customer_df = pd.DataFrame(customer_data)
                customer_performance = customer_df.groupby("å®¢æˆ¶åç¨±").agg({
                    "ç¸½è¨ˆ": "sum",
                    "æº–æ™‚": "sum"
                }).reset_index()
                
                customer_performance.columns = ["å®¢æˆ¶åç¨±", "æœ‰æ•ˆç­†æ•¸", "æº–æ™‚ç­†æ•¸"]
                customer_performance["å»¶é²ç­†æ•¸"] = customer_performance["æœ‰æ•ˆç­†æ•¸"] - customer_performance["æº–æ™‚ç­†æ•¸"]
                customer_performance["é”äº¤ç‡(%)"] = (customer_performance["æº–æ™‚ç­†æ•¸"] / customer_performance["æœ‰æ•ˆç­†æ•¸"] * 100).round(2)
                customer_performance = customer_performance.sort_values("é”äº¤ç‡(%)", ascending=False)
                
                # æ ¼å¼åŒ–å®¢æˆ¶è¡¨ç¾æ•¸æ“š
                display_customer_performance = customer_performance.copy()
                for col in ["æœ‰æ•ˆç­†æ•¸", "æº–æ™‚ç­†æ•¸", "å»¶é²ç­†æ•¸"]:
                    if col in display_customer_performance.columns:
                        display_customer_performance[col] = display_customer_performance[col].apply(lambda x: format_number_with_comma(x))
                display_customer_performance["é”äº¤ç‡(%)"] = display_customer_performance["é”äº¤ç‡(%)"].apply(lambda x: f"{x:.2f}%")
                
                st.dataframe(display_customer_performance, use_container_width=True)
                
                st.download_button(
                    "ğŸ“¥ ä¸‹è¼‰å®¢æˆ¶è¡¨ç¾åˆ†æ",
                    data=customer_performance.to_csv(index=False).encode("utf-8-sig"),
                    file_name="å®¢æˆ¶é”äº¤è¡¨ç¾.csv",
                    mime="text/csv",
                )

def enhanced_area_analysis(df: pd.DataFrame, col_map: Dict[str, Optional[str]], exclude_swi_mask: pd.Series, topn_cities: int) -> None:
    """å¢å¼·ç‰ˆé…é€å€åŸŸåˆ†æ"""
    st.markdown('<h2 class="section-header">â‘¢ é…é€å€åŸŸåˆ†æ</h2>', unsafe_allow_html=True)
    
    address_col = col_map.get("address")
    cust_name_col = col_map.get("cust_name")
    
    if not address_col or address_col not in df.columns:
        st.error("âš ï¸ æ‰¾ä¸åˆ°ã€åœ°å€ã€æ¬„ä½")
        return
    
    # è™•ç†å€åŸŸè³‡æ–™
    region_df = df[exclude_swi_mask].copy()
    region_df["ç¸£å¸‚"] = region_df[address_col].apply(enhanced_city_extraction)
    region_df["ç¸£å¸‚"] = region_df["ç¸£å¸‚"].fillna("(æœªçŸ¥)")
    
    city_stats = region_df["ç¸£å¸‚"].value_counts().reset_index()
    city_stats.columns = ["ç¸£å¸‚", "ç­†æ•¸"]
    
    total_records = city_stats["ç­†æ•¸"].sum()
    city_stats["ä½”æ¯”(%)"] = (city_stats["ç­†æ•¸"] / total_records * 100).round(2)
    
    # å€åŸŸæŒ‡æ¨™
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        create_enhanced_metric_card("ç¸½é…é€ç­†æ•¸", f"{total_records:,}")
    with col2:
        valid_cities = len(city_stats[city_stats["ç¸£å¸‚"] != "(æœªçŸ¥)"])
        create_enhanced_metric_card("è¦†è“‹ç¸£å¸‚æ•¸", f"{valid_cities}")
    with col3:
        main_city = city_stats.iloc[0]["ç¸£å¸‚"] if not city_stats.empty else "ç„¡"
        main_count = city_stats.iloc[0]["ç­†æ•¸"] if not city_stats.empty else 0
        create_enhanced_metric_card("ä¸»è¦é…é€å€", main_city, f"{main_count}ç­†")
    with col4:
        unknown_count = city_stats[city_stats["ç¸£å¸‚"] == "(æœªçŸ¥)"]["ç­†æ•¸"].sum()
        unknown_rate = unknown_count / total_records * 100 if total_records > 0 else 0
        create_enhanced_metric_card("åœ°å€è­˜åˆ¥ç‡", f"{100-unknown_rate:.1f}%")
    
    # è©³ç´°åˆ†æ
    tab1, tab2 = st.tabs(["ğŸ—ºï¸ ç¸£å¸‚åˆ†ä½ˆ", "ğŸ¢ å®¢æˆ¶å€åŸŸ"])
    
    with tab1:
        col1, col2 = st.columns([1, 1])
        with col1:
            # æ ¼å¼åŒ–ç¸£å¸‚çµ±è¨ˆæ•¸æ“š
            display_city_stats = city_stats.copy()
            display_city_stats["ç­†æ•¸"] = display_city_stats["ç­†æ•¸"].apply(lambda x: format_number_with_comma(x))
            display_city_stats["ä½”æ¯”(%)"] = display_city_stats["ä½”æ¯”(%)"].apply(lambda x: f"{x:.2f}%")
            
            st.dataframe(display_city_stats, use_container_width=True, height=400)
        with col2:
            fig_map = px.bar(
                city_stats.head(15), 
                x="ç¸£å¸‚", 
                y="ç­†æ•¸",
                title="å‰15ç¸£å¸‚é…é€é‡",
                color_discrete_sequence=COLORFUL_PALETTE
            )
            fig_map.update_layout(xaxis_tickangle=-45)
            st.plotly_chart(fig_map, use_container_width=True)
        
        st.download_button(
            "ğŸ“¥ ä¸‹è¼‰ç¸£å¸‚çµ±è¨ˆ",
            data=city_stats.to_csv(index=False).encode("utf-8-sig"),
            file_name="ç¸£å¸‚é…é€çµ±è¨ˆ.csv",
            mime="text/csv",
        )
    
    with tab2:
        if cust_name_col and cust_name_col in region_df.columns:
            customer_city_analysis = region_df.groupby([cust_name_col, "ç¸£å¸‚"]).size().reset_index(name="ç­†æ•¸")
            customer_city_analysis["å®¢æˆ¶ç¸½ç­†æ•¸"] = customer_city_analysis.groupby(cust_name_col)["ç­†æ•¸"].transform("sum")
            customer_city_analysis["ç¸£å¸‚ä½”æ¯”(%)"] = (
                customer_city_analysis["ç­†æ•¸"] / customer_city_analysis["å®¢æˆ¶ç¸½ç­†æ•¸"] * 100
            ).round(2)
            
            # å–æ¯å®¢æˆ¶å‰Nå€‹ç¸£å¸‚
            top_customer_cities = (
                customer_city_analysis
                .sort_values("ç­†æ•¸", ascending=False)
                .groupby(cust_name_col)
                .head(topn_cities)
                .sort_values([cust_name_col, "ç­†æ•¸"], ascending=[True, False])
            )
            
            # æ ¼å¼åŒ–å®¢æˆ¶å€åŸŸæ•¸æ“š
            display_cities = top_customer_cities.rename(columns={cust_name_col: "å®¢æˆ¶åç¨±"}).copy()
            for col in ["ç­†æ•¸", "å®¢æˆ¶ç¸½ç­†æ•¸"]:
                if col in display_cities.columns:
                    display_cities[col] = display_cities[col].apply(lambda x: format_number_with_comma(x))
            display_cities["ç¸£å¸‚ä½”æ¯”(%)"] = display_cities["ç¸£å¸‚ä½”æ¯”(%)"].apply(lambda x: f"{x:.2f}%")
            
            st.dataframe(display_cities, use_container_width=True)
            
            st.download_button(
                "ğŸ“¥ ä¸‹è¼‰å®¢æˆ¶å€åŸŸåˆ†æ",
                data=top_customer_cities.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"å®¢æˆ¶å€åŸŸåˆ†æ_Top{topn_cities}.csv",
                mime="text/csv",
            )

def enhanced_loading_analysis(df: pd.DataFrame, col_map: Dict[str, Optional[str]], exclude_swi_mask: pd.Series) -> None:
    """å¢å¼·ç‰ˆé…é€è£è¼‰åˆ†æ"""
    st.markdown('<h2 class="section-header">â‘£ é…é€è£è¼‰åˆ†æ</h2>', unsafe_allow_html=True)
    
    ship_no_col = col_map.get("ship_no")
    status_col = col_map.get("status")
    
    if not ship_no_col or ship_no_col not in df.columns:
        st.error("âš ï¸ æ‰¾ä¸åˆ°ã€å‡ºåº«å–®è™Ÿã€æ¬„ä½")
        return
    
    # ç¯©é¸æ¢ä»¶
    base_mask = exclude_swi_mask.copy()
    if status_col and status_col in df.columns:
        completed_mask = df[status_col].astype(str).str.strip() == "å®Œæˆ"
        base_mask &= completed_mask
        st.info("âœ… å·²å¥—ç”¨ç‹€æ…‹ç¯©é¸ï¼šåƒ…é¡¯ç¤ºã€å®Œæˆã€ç‹€æ…‹çš„è¨˜éŒ„")
    
    loading_df = df[base_mask].copy()
    
    if loading_df.empty:
        st.warning("ç„¡ç¬¦åˆæ¢ä»¶çš„è£è¼‰æ•¸æ“š")
        return
    
    # è»Šæ¬¡ä»£ç¢¼ç”Ÿæˆ
    loading_df["è»Šæ¬¡ä»£ç¢¼"] = loading_df[ship_no_col].astype(str).str[:13]
    
    # æ•¸å€¼æ¬„ä½è™•ç†
    numeric_cols = ["qty", "copper_ton", "fg_net_ton", "fg_gross_ton"]
    for col_key in numeric_cols:
        col_name = col_map.get(col_key)
        if col_name and col_name in loading_df.columns:
            loading_df[f"_{col_key}_numeric"] = pd.to_numeric(loading_df[col_name], errors="coerce")
    
    # è½‰æ›éŠ…é‡é‡ç‚ºå™¸
    if "_copper_ton_numeric" in loading_df.columns:
        loading_df["_copper_ton_converted"] = loading_df["_copper_ton_numeric"] / 1000.0
    
    # å»ºç«‹å±•ç¤ºè³‡æ–™
    display_data = {"è»Šæ¬¡ä»£ç¢¼": loading_df["è»Šæ¬¡ä»£ç¢¼"], "å‡ºåº«å–®è™Ÿ": loading_df[ship_no_col]}
    
    # å¯é¸æ¬„ä½
    optional_mappings = {
        "DOè™Ÿ": "do_no",
        "æ–™è™Ÿèªªæ˜": "item_desc", 
        "æ‰¹æ¬¡": "lot_no",
        "å®¢æˆ¶åç¨±": "cust_name"
    }
    
    for display_name, map_key in optional_mappings.items():
        col_name = col_map.get(map_key)
        if col_name and col_name in loading_df.columns:
            display_data[display_name] = loading_df[col_name]
    
    # æ•¸å€¼æ¬„ä½
    numeric_mappings = {
        "å‡ºè²¨æ•¸é‡": "_qty_numeric",
        "éŠ…é‡é‡(å™¸)": "_copper_ton_converted", 
        "æˆå“æ·¨é‡(å™¸)": "_fg_net_ton_numeric",
        "æˆå“æ¯›é‡(å™¸)": "_fg_gross_ton_numeric"
    }
    
    for display_name, internal_name in numeric_mappings.items():
        if internal_name in loading_df.columns:
            display_data[display_name] = loading_df[internal_name].round(3)
    
    detailed_loading_df = pd.DataFrame(display_data)
    
    # æ’åº
    if "è»Šæ¬¡ä»£ç¢¼" in detailed_loading_df.columns:
        detailed_loading_df = detailed_loading_df.sort_values(["è»Šæ¬¡ä»£ç¢¼", "å‡ºåº«å–®è™Ÿ"]).reset_index(drop=True)
    
    # è»Šæ¬¡å½™ç¸½
    trip_summary_data = []
    for trip_code in loading_df["è»Šæ¬¡ä»£ç¢¼"].unique():
        trip_data = loading_df[loading_df["è»Šæ¬¡ä»£ç¢¼"] == trip_code]
        summary_row = {"è»Šæ¬¡ä»£ç¢¼": trip_code}
        
        for display_name, internal_name in numeric_mappings.items():
            if internal_name in loading_df.columns:
                summary_row[f"{display_name}å°è¨ˆ"] = trip_data[internal_name].sum()
        
        trip_summary_data.append(summary_row)
    
    trip_summary = pd.DataFrame(trip_summary_data)
    for col in trip_summary.columns:
        if "å°è¨ˆ" in col and trip_summary[col].dtype in ['float64', 'int64']:
            trip_summary[col] = trip_summary[col].round(3)
    
    # åˆ†ææ¨™ç±¤
    load_tab1, load_tab2, load_tab3 = st.tabs(["ğŸ“¦ è£è¼‰æ˜ç´°", "ğŸš› è»Šæ¬¡å½™ç¸½", "ğŸ“Š è£è¼‰åˆ†æ"])
    
    with load_tab1:
        st.dataframe(detailed_loading_df, use_container_width=True, height=500)
        st.download_button(
            "ğŸ“¥ ä¸‹è¼‰è£è¼‰æ˜ç´°",
            data=detailed_loading_df.to_csv(index=False).encode("utf-8-sig"),
            file_name="é…é€è£è¼‰æ˜ç´°.csv",
            mime="text/csv",
        )
    
    with load_tab2:
        total_trips = len(trip_summary)
        col1, col2, col3 = st.columns(3)
        with col1:
            create_enhanced_metric_card("ç¸½è»Šæ¬¡æ•¸", f"{total_trips:,}")
        with col2:
            if not detailed_loading_df.empty:
                avg_items = detailed_loading_df.groupby("è»Šæ¬¡ä»£ç¢¼").size().mean()
                create_enhanced_metric_card("å¹³å‡æ¯è»Šé …ç›®æ•¸", f"{avg_items:.1f}")
        with col3:
            copper_col = "éŠ…é‡é‡(å™¸)å°è¨ˆ"
            if copper_col in trip_summary.columns:
                valid_weights = trip_summary[trip_summary[copper_col] > 0][copper_col]
                avg_weight = valid_weights.mean() if not valid_weights.empty else 0
                create_enhanced_metric_card("å¹³å‡è¼‰é‡(å™¸)", f"{avg_weight:.2f}")
        
        st.dataframe(trip_summary, use_container_width=True)
        
        st.download_button(
            "ğŸ“¥ ä¸‹è¼‰è»Šæ¬¡å½™ç¸½",
            data=trip_summary.to_csv(index=False).encode("utf-8-sig"),
            file_name="è»Šæ¬¡å½™ç¸½çµ±è¨ˆ.csv",
            mime="text/csv",
        )
    
    with load_tab3:
        copper_col = "éŠ…é‡é‡(å™¸)å°è¨ˆ"
        if copper_col in trip_summary.columns:
            weight_data = trip_summary[trip_summary[copper_col] > 0][copper_col]
            
            if not weight_data.empty and len(weight_data) > 1:
                fig_dist = go.Figure()
                fig_dist.add_trace(go.Histogram(
                    x=weight_data,
                    nbinsx=min(20, len(weight_data)),
                    name="è¼‰é‡åˆ†ä½ˆ",
                    marker_color=COLORFUL_PALETTE[0],
                    opacity=0.8
                ))
                fig_dist.update_layout(
                    title="è»Šè¼›è¼‰é‡åˆ†ä½ˆç›´æ–¹åœ–",
                    xaxis_title="è¼‰é‡(å™¸)",
                    yaxis_title="è»Šæ¬¡æ•¸",
                    plot_bgcolor='white'
                )
                st.plotly_chart(fig_dist, use_container_width=True)
                
                # çµ±è¨ˆæ‘˜è¦
                stats_data = {
                    "çµ±è¨ˆé …ç›®": ["æœ€å°è¼‰é‡", "æœ€å¤§è¼‰é‡", "å¹³å‡è¼‰é‡", "ä¸­ä½æ•¸è¼‰é‡", "æ¨™æº–å·®"],
                    "æ•¸å€¼(å™¸)": [
                        f"{weight_data.min():.3f}",
                        f"{weight_data.max():.3f}",
                        f"{weight_data.mean():.3f}",
                        f"{weight_data.median():.3f}",
                        f"{weight_data.std():.3f}"
                    ]
                }
                st.dataframe(pd.DataFrame(stats_data), use_container_width=True)

# ========================
# ä¸»ç¨‹å¼æµç¨‹
# ========================

def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    
    if not EXCEL_AVAILABLE:
        st.warning("âš ï¸ æœªå®‰è£ openpyxlï¼ŒExcel åŠŸèƒ½å°‡å—é™")
    
    # æª”æ¡ˆä¸Šå‚³
    st.markdown("### ğŸ“ æª”æ¡ˆä¸Šå‚³")
    uploaded_file = st.file_uploader(
        "é¸æ“‡æ‚¨çš„æ•¸æ“šæª”æ¡ˆ",
        type=["xlsx", "xls", "csv"],
        help="æ”¯æ´æ ¼å¼ï¼šExcel (.xlsx, .xls) å’Œ CSV (.csv)",
        accept_multiple_files=False
    )
    
    if not uploaded_file:
        st.markdown("### ğŸ“– ä½¿ç”¨èªªæ˜")
        st.info("""
        **åŠŸèƒ½æ¦‚è¿°ï¼š**
        - ğŸ“Š **å‡ºè²¨é¡å‹åˆ†æ**ï¼šçµ±è¨ˆå„é¡å‹ç­†æ•¸èˆ‡éŠ…é‡é‡
        - ğŸšš **é”äº¤ç‡åˆ†æ**ï¼šè¨ˆç®—æº–æ™‚äº¤ä»˜ç‡ï¼Œè­˜åˆ¥å»¶é²å•é¡Œ  
        - ğŸ—ºï¸ **å€åŸŸåˆ†æ**ï¼šåˆ†æé…é€åœ°å€åˆ†ä½ˆèˆ‡å®¢æˆ¶åå¥½
        - ğŸ“¦ **è£è¼‰åˆ†æ**ï¼šè»Šæ¬¡è£è¼‰çµ±è¨ˆèˆ‡æ•ˆç‡åˆ†æ
        """)
        return
    
    # è¼‰å…¥è³‡æ–™
    file_extension = uploaded_file.name.split(".")[-1].lower()
    
    with st.spinner("æ­£åœ¨è™•ç†æª”æ¡ˆ..."):
        df = load_data(uploaded_file, file_extension)
    
    if df.empty:
        st.error("æª”æ¡ˆè¼‰å…¥å¤±æ•—æˆ–æª”æ¡ˆç‚ºç©º")
        return
    
    st.success(f"âœ… æˆåŠŸè¼‰å…¥ {len(df):,} ç­†è¨˜éŒ„ï¼Œ{len(df.columns)} å€‹æ¬„ä½")
    
    # è‡ªå‹•åµæ¸¬æ¬„ä½
    auto_mapping = smart_column_detector(df.columns.tolist())
    
    # ä¸»è¦é ç±¤
    main_tab1, main_tab2 = st.tabs(["ğŸ“Š æ•¸æ“šåˆ†æ", "ğŸ“„ åŸå§‹æ•¸æ“š"])
    
    with main_tab2:
        st.markdown("### åŸå§‹æ•¸æ“šé è¦½")
        st.dataframe(df, use_container_width=True, height=600)
        
        st.markdown("### ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ")
        basic_stats = pd.DataFrame({
            "é …ç›®": ["ç¸½è¨˜éŒ„æ•¸", "æ¬„ä½æ•¸", "ç©ºå€¼ç¸½æ•¸", "é‡è¤‡è¨˜éŒ„æ•¸"],
            "æ•¸å€¼": [
                f"{len(df):,}",
                f"{len(df.columns)}",
                f"{df.isnull().sum().sum():,}",
                f"{df.duplicated().sum():,}"
            ]
        })
        st.dataframe(basic_stats, use_container_width=True)
    
    with main_tab1:
        # å´é‚Šæ¬„ç¯©é¸
        with st.sidebar:
            st.markdown("### âš™ï¸ åˆ†ææ§åˆ¶é¢æ¿")
            
            with st.expander("ğŸ” é€šç”¨ç¯©é¸", expanded=True):
                # å‡ºè²¨é¡å‹ç¯©é¸
                selected_ship_types = []
                if auto_mapping.get("ship_type"):
                    unique_types = sorted(df[auto_mapping["ship_type"]].dropna().unique())
                    selected_ship_types = st.multiselect(
                        "å‡ºè²¨ç”³è«‹é¡å‹", 
                        options=unique_types,
                        default=[]
                    )
                
                # å®¢æˆ¶åç¨±ç¯©é¸
                selected_customers = []
                if auto_mapping.get("cust_name"):
                    unique_customers = sorted(df[auto_mapping["cust_name"]].dropna().unique())
                    selected_customers = st.multiselect(
                        "å®¢æˆ¶åç¨±",
                        options=unique_customers[:100],
                        default=[]
                    )
                
                # å®¢æˆ¶ç·¨è™Ÿç¯©é¸
                selected_cust_ids = []
                if auto_mapping.get("cust_id"):
                    unique_cust_ids = sorted(df[auto_mapping["cust_id"]].dropna().unique())
                    selected_cust_ids = st.multiselect(
                        "å®¢æˆ¶ç·¨è™Ÿ",
                        options=unique_cust_ids[:100],
                        default=[]
                    )
                
                # æ–™è™Ÿèªªæ˜ç¯©é¸
                selected_item_descs = []
                if auto_mapping.get("item_desc"):
                    unique_items = sorted(df[auto_mapping["item_desc"]].dropna().unique())
                    selected_item_descs = st.multiselect(
                        "æ–™è™Ÿèªªæ˜",
                        options=unique_items[:100],
                        default=[]
                    )
                
                # æ—¥æœŸç¯©é¸
                date_range = None
                if auto_mapping.get("due_date"):
                    due_dates = safe_datetime_convert(df[auto_mapping["due_date"]])
                    if due_dates.notna().any():
                        min_date = due_dates.min().date()
                        max_date = due_dates.max().date()
                        date_range = st.date_input(
                            "æŒ‡å®šåˆ°è²¨æ—¥æœŸç¯„åœ",
                            value=(min_date, max_date),
                            min_value=min_date,
                            max_value=max_date
                        )
            
            with st.expander("âš™ï¸ é€²éšè¨­å®š"):
                topn_cities = st.slider("æ¯å®¢æˆ¶é¡¯ç¤ºå‰Nå€‹é…é€ç¸£å¸‚", 1, 10, 3)
        
        # å¥—ç”¨ç¯©é¸
        filtered_df = df.copy()
        
        if selected_ship_types and auto_mapping.get("ship_type"):
            filtered_df = filtered_df[filtered_df[auto_mapping["ship_type"]].isin(selected_ship_types)]
        
        if selected_customers and auto_mapping.get("cust_name"):
            filtered_df = filtered_df[filtered_df[auto_mapping["cust_name"]].isin(selected_customers)]
        
        if date_range and len(date_range) == 2 and auto_mapping.get("due_date"):
            start_date = pd.to_datetime(date_range[0])
            end_date = pd.to_datetime(date_range[1])
            due_dates = safe_datetime_convert(filtered_df[auto_mapping["due_date"]])
            date_mask = (due_dates >= start_date) & (due_dates <= end_date)
            filtered_df = filtered_df[date_mask]
        
        if len(filtered_df) != len(df):
            st.info(f"ğŸ” ç¯©é¸å¾Œé¡¯ç¤º {len(filtered_df):,} ç­†è¨˜éŒ„ï¼ˆåŸå§‹ï¼š{len(df):,} ç­†ï¼‰")
        
        # SWIæ’é™¤é‚è¼¯
        exclude_swi = pd.Series(True, index=filtered_df.index)
        if auto_mapping.get("ship_type"):
            exclude_swi = filtered_df[auto_mapping["ship_type"]] != "SWI-å¯„åº«"
        
        # åŸ·è¡Œåˆ†æ
        if not filtered_df.empty:
            enhanced_shipment_analysis(filtered_df, auto_mapping)
            st.markdown("---")
            enhanced_delivery_performance(filtered_df, auto_mapping, exclude_swi)
            st.markdown("---") 
            enhanced_area_analysis(filtered_df, auto_mapping, exclude_swi, topn_cities)
            st.markdown("---")
            enhanced_loading_analysis(filtered_df, auto_mapping, exclude_swi)
        else:
            st.warning("âš ï¸ ç¯©é¸æ¢ä»¶éæ–¼åš´æ ¼ï¼Œç„¡æ•¸æ“šå¯é¡¯ç¤º")

if __name__ == "__main__":
    main()
